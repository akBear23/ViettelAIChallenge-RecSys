{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b0bd5b-ab7c-4f5f-b23d-7fd32c050577",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Change file here\n",
    "pwd = os.getcwd()\n",
    "train_file = f\"{pwd}/data/training_set.csv\"\n",
    "public_test_file = f\"{pwd}data/public_testset.csv\"\n",
    "private_test_file = f\"{pwd}/data/test_set_private.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a102dc6-7a9b-4cab-9d4a-0ccd6d00db63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store runs predict path\n",
    "out_path = f\"{pwd}/runs/private-test-attempt-final\"\n",
    "import os \n",
    "os.makedirs(out_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f765770-0887-44e4-8527-39b66f25f1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1095162e-2472-4666-bc16-23897966b482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose GPU to use\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639f5efa-f6d2-4233-b0ef-9fc694f3c896",
   "metadata": {},
   "source": [
    "# SELFRec Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f3eb5c-a572-400c-a7be-c7a5f156b0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd $pwd/SELFRec/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e79fdf-4f52-4089-94e2-840ad15e22e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from base.torch_interface import TorchGraphInterface\n",
    "from base.graph_recommender import GraphRecommender\n",
    "from data.loader import FileIO\n",
    "from util.conf import ModelConf\n",
    "from util.sampler import next_batch_pairwise\n",
    "from util.loss_torch import bpr_loss, l2_reg_loss, InfoNCE\n",
    "\n",
    "from model.graph.LightGCN import *\n",
    "from model.graph.XSimGCL import *\n",
    "from model.graph.DirectAU import *\n",
    "from model.graph.SimGCL import *\n",
    "from SELFRec import SELFRec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b29f50-da83-42ef-8014-b268bad13aaf",
   "metadata": {},
   "source": [
    "## Get result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eef1dc2-f424-468e-92ac-48b5d2924ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df = pd.read_csv(private_test_file, names=['user_id'] + [f'item_id_{i}' for i in range(1,1001)])\n",
    "predict_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9e7090-75f7-4b48-b5ca-14b12dcc6b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = {\n",
    "    \"LightGCN\": f\"{pwd}/runs/LightGCN/model.pkl\",\n",
    "    \"XSimGCL\": f\"{pwd}/runs/XSimGCL/model.pkl\",\n",
    "    \"DirectAU\": f\"{pwd}/runs/DirectAU/model.pkl\",\n",
    "    \"SimGCL\": f\"{pwd}/runs/SimGCL/model.pkl\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc23993-8fe5-4d0d-84e6-24b90469bf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.algorithm import find_k_largest\n",
    "def test(self):\n",
    "    def process_bar(num, total):\n",
    "        rate = float(num) / total\n",
    "        ratenum = int(50 * rate)\n",
    "        print(f'\\rProgress: [{\"+\" * ratenum}{\" \" * (50 - ratenum)}]{ratenum * 2}%', end='', flush=True)\n",
    "\n",
    "    rec_list = {}\n",
    "    data_train = pd.DataFrame(self.data.training_data, columns= ['uid', 'iid', 'rating'])\n",
    "    self.data.train_set = data_train[data_train['uid'].isin(test_user_id)].values.tolist()\n",
    "    user_count = len(self.data.train_set)\n",
    "    \n",
    "    for i, user in enumerate(self.data.train_set):\n",
    "        user = user[0]\n",
    "        candidates = self.predict(user)\n",
    "        rated_list, _ = self.data.user_rated(user)\n",
    "        for item in rated_list:\n",
    "            candidates[self.data.item[item]] = -10e8\n",
    "        # ids, scores = find_k_largest(1000, candidates)\n",
    "        item_names = predict_df[predict_df.user_id == user].values[0][1:]\n",
    "        scores = []\n",
    "        for item in item_names:\n",
    "            try:\n",
    "                id_tmp = self.data.item[item]\n",
    "                scores.append(candidates[id_tmp])\n",
    "            except:\n",
    "                # Cần sửa khuyến nghị cold start\n",
    "                scores.append(0)\n",
    "        \n",
    "        sorted_list = sorted(list(zip(item_names, scores)), key=lambda x: x[1], reverse=True)\n",
    "        rec_list[user] = sorted_list\n",
    "        if i % 1000 == 0:\n",
    "            process_bar(i, user_count)\n",
    "    process_bar(user_count, user_count)\n",
    "    print('')\n",
    "    return rec_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4387bc1d-e7a3-4adb-a851-6c541678ca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numba\n",
    "import gc\n",
    "import torch\n",
    "for model, path in model_path.items():\n",
    "    with open(path, \"rb\") as f:\n",
    "        rec = pickle.load(f)\n",
    "\n",
    "    rec_list = test(rec)\n",
    "\n",
    "    data = []\n",
    "    for user_id in test_user_id:\n",
    "        data.append([user_id] + [i[0] for i in rec_list[user_id]])\n",
    "\n",
    "    pd.DataFrame(data).to_csv(f'{out_path}/{model}_predict.csv', index = False, header=False)\n",
    "\n",
    "    del rec\n",
    "    gc.collect()  # collecting garbage\n",
    "    torch.cuda.empty_cache()  # cleaning GPU cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562fd541-8894-4b08-a12e-d99daa40064b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# RecVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf45690-3b82-4bde-b459-d0db4403fca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd $pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75fb15a-be49-48b4-91b1-37d88815cbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_checkpoint = f\"{{pwd}}/runs/RecVAE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7a7719-5740-4362-aee9-c6a75879e3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{vae_checkpoint}/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bba6e80-ba1e-4008-830e-458af0c514f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(f\"{private_test_file}\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2890ace4-6848-43b7-abe1-a6c3abcffd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2item_df = pd.read_csv(f\"{vae_checkpoint}/unique_sid.txt\", header=None).rename(columns={0: \"ItemId\"}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4419c37f-0aa4-44d0-8d00-c73ac5a2a8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tr = df[df[\"UserId\"].isin(test[0].values)]\n",
    "test_tr = test_tr.merge(id2item_df, how=\"inner\", on=\"ItemId\").rename(columns={\"index\": \"sid\"})\n",
    "user_test = pd.DataFrame(test_tr[\"UserId\"].unique(), columns=[\"UserId\"]).reset_index().rename(columns={\"index\" : \"uid\"})\n",
    "test_tr = pd.merge(test_tr, user_test, on=\"UserId\")\n",
    "test_tr[[\"uid\", \"sid\"]].to_csv(f\"{vae_checkpoint}/testset_recvae.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536ecb67-3abb-4636-98af-5920c0ea4aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python recvae/infer.py --dataset $vae_checkpoint --hidden-dim 3072 --latent-dim 2048 --infer_data $vae_checkpoint/testset_recvae.csv --model_path $vae_checkpoint/model.pt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a4a883-ccb2-4c78-a4da-0774434c85bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(f\"{vae_checkpoint}/result_csp.pkl\", \"rb\") as f:\n",
    "    result = pickle.load(f)\n",
    "\n",
    "id2profile = dict(user_test.values)\n",
    "profile2id = {value: key for key, value in id2profile.items()}\n",
    "id2item = dict(id2item_df.values)\n",
    "item2id = {value: key for key, value in id2item.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8403a09e-1e96-4fff-9ca2-1a9b88af33dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "return_list = []\n",
    "for r in tqdm(test.merge(user_test, left_on=0, right_on=\"UserId\", how=\"left\").values):\n",
    "    userid = r[0]\n",
    "    list_item = r[1:1001]\n",
    "    uid = r[1001]\n",
    "    \n",
    "    # Process User not in Test By get the default list\n",
    "    if np.isnan(uid):\n",
    "        return_list.append([userid, *list_item])\n",
    "        continue\n",
    "\n",
    "    # Convert ItemId to indexs of sparse vector\n",
    "    item_indexs = []\n",
    "    for l in list_item:\n",
    "        try:\n",
    "            item_indexs.append((item2id[l], l))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Score and sorted to get to recommend item\n",
    "    scored_item = []\n",
    "    indexes, itemids = map(list,zip(*item_indexs))\n",
    "    for item, score in zip(itemids, result[int(uid)][indexes]):\n",
    "        scored_item.append((item, score))\n",
    "\n",
    "    scored_item = sorted(scored_item, key=lambda x : x[1], reverse=True)\n",
    "    recommend_list, _ = map(list,zip(*scored_item))\n",
    "\n",
    "    # Append to return list to make submit\n",
    "    return_list.append([userid, *recommend_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df42bd55-e14e-4d40-91c3-a76f4b64622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_df = pd.DataFrame(return_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11d3472-6dd7-4baa-9109-c89915d29c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917077f6-3da4-447c-abd7-0d9cd3fdeaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill remanining cells as nan value to make submit file eligible\n",
    "for i in range(len(return_df.columns), 1001):\n",
    "    return_df[i] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fa9cbb-88dd-4d9b-930f-b78712657458",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_df.fillna(\"0\").to_csv(f\"{out_path}/predict_RecVAE.csv\", header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267b1ba2-27d1-4bcd-a983-3affa7f95dab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7f1489-c63c-4f87-8811-77c1efe2bb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "als_checkpoint = f\"{pwd}/runs/ALS/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2776be61-58fe-4f1f-8ac0-f71c54ec6eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "   \n",
    "with open(f\"{als_checkpoint}/model.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "with open(f\"{als_checkpoint}/usermap.pkl\", \"rb\") as f:\n",
    "    user_map = pickle.load(f)\n",
    "\n",
    "with open(f\"{als_checkpoint}/itemmap.pkl\", \"rb\") as f:\n",
    "    item_map = pickle.load(f)\n",
    "\n",
    "with open(f\"{als_checkpoint}/csr_train.pkl\", \"rb\") as f:\n",
    "    csr_train = pickle.load(f)\n",
    "\n",
    "user_ids = {v:k for k, v in user_map.items()}\n",
    "item_ids = {v:k for k, v in item_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccecf3d4-f311-489d-84ab-af17e6bc05dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; os.environ['OPENBLAS_NUM_THREADS']='1'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import implicit\n",
    "from scipy.sparse import coo_matrix\n",
    "from implicit.evaluation import mean_average_precision_at_k\n",
    "from implicit.evaluation import ndcg_at_k\n",
    "from implicit.gpu import matrix_factorization_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc8fd72-54a6-4045-99be-8c245aeca275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(model, csr_train, test_user_id, item_names, submission_name=\"predict_BPR.csv\"):\n",
    "    preds = []\n",
    "    batch_size = 2000\n",
    "    # Make sure we're only predicting for users in test_user_id\n",
    "    to_generate = np.array([user_id for user_id in test_user_index])  # Make sure users exist in user_ids\n",
    "    \n",
    "    for startidx in range(0, len(to_generate), batch_size):\n",
    "        batch = to_generate[startidx:startidx + batch_size]\n",
    "        # print(batch)\n",
    "        ids, scores = model.recommend(batch, csr_train[batch], N=1000, filter_already_liked_items=True)\n",
    "        \n",
    "        for i, userid in enumerate(batch):\n",
    "            customer_id = user_ids[userid]\n",
    "            user_items = ids[i]\n",
    "            \n",
    "            # Filter the items to keep only those in item_names for the current user\n",
    "            valid_item_ids = [item for item in user_items if item_ids[item] in item_names[customer_id]]\n",
    "            \n",
    "            # If fewer than 1000 items are valid, fill the rest with invalid items or random items\n",
    "            # You can adjust the fill logic if needed, here it's just taking invalid items or the first items.\n",
    "            invalid_items = [item for item in user_items if item_ids[item] not in item_names[customer_id]]\n",
    "            filled_items = valid_item_ids + invalid_items[:(1000 - len(valid_item_ids))]\n",
    "            \n",
    "            # Ensure we have exactly 1000 items\n",
    "            article_ids = [item_ids[item_id] for item_id in filled_items[:1000]]\n",
    "            \n",
    "            preds.append([customer_id] + article_ids)\n",
    "    \n",
    "    # Create the DataFrame for submission\n",
    "    df_preds = pd.DataFrame(preds, columns=['customer_id'] + [f'item_{i}' for i in range(1000)])\n",
    "    df_preds.to_csv(submission_name, index=False, header=False)\n",
    "    \n",
    "    display(df_preds.head())\n",
    "    print(df_preds.shape)\n",
    "    \n",
    "    return df_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc4877e-2867-4686-98df-d3364027714e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(f\"{pwd}/data/test_set_private.csv\", names=['user_id'] + [f'item_id_{i}' for i in range(1,1001)])\n",
    "test_user_id = test['user_id'].values\n",
    "\n",
    "test['user_index'] = test['user_id'].map(user_map)\n",
    "test_user_index = test['user_index'].values\n",
    "\n",
    "item_names = {}\n",
    "for user_id in test_user_id:\n",
    "    item_names[user_id] = test[test.user_id == user_id].values[0][1:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df45bd1f-bfc2-4ef9-9413-9d0209f05da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df_preds = submit(model, csr_train, test_user_id, item_names);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bb8cbc-9b18-4586-bfdf-ced4241d42dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds.fillna(\"0\").to_csv(f\"{out_path}/predict_ALS.csv\", header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb1b8b4-2b4a-4ade-9abf-963a9ef213f1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# SAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a0ea76-10d3-4ca4-8b1b-8c909b9c7494",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd $pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7ab3dc-48f5-4e6e-9cdc-edcabafd272c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('data/test_set_private.csv', names=['user_id'] + [f'item_id_{i}' for i in range(1,1001)])\n",
    "test_user_id = test_df['user_id'].values\n",
    "\n",
    "test_df['user_id'] = test_df['user_id'].astype('category')\n",
    "for i in range(1,1001):\n",
    "    test_df[f'item_id_{i}'] = test_df[f'item_id_{i}'].astype('category')\n",
    "\n",
    "test_df['UserId'] = test_df['user_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df64403-a67d-4042-b770-65b5c0a80933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"runs/SAR/model.pkl\", \"rb\") as f\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa609ca-71ca-4dad-9f1c-cf86cbf1b5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(data, batch_size):\n",
    "    for start in range(0, len(data), batch_size):\n",
    "        end = min(start + batch_size, len(data))\n",
    "        yield data[start:end]\n",
    "\n",
    "batch_size = 1000  # Adjust batch size as needed\n",
    "all_recommendations = []\n",
    "\n",
    "for user_batch in batch_generator(test_df['UserId'].unique(), batch_size):\n",
    "    # Filter the test data for the current user batch\n",
    "    user_batch_data = test_df[test_df['UserId'].isin(user_batch)]\n",
    "    recommendations = model.recommend_k_items(user_batch_data, top_k=1200, remove_seen=True)\n",
    "    all_recommendations.append(recommendations)\n",
    "\n",
    "# Combine all recommendations\n",
    "all_recommendations = pd.concat(all_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9aed85-4e59-42fa-8273-e41983e58190",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_recommendations.to_csv('DS/data/SAR_recommendations_no_timestamp_tail19.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54eeeddb-b390-4cf5-a4eb-dff0dfd1ec01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "preds = []  # Result storage\n",
    "\n",
    "for user_id in tqdm(test_user_id):\n",
    "    # Retrieve item names and candidate pairs for this user\n",
    "    item_names = predict_df[predict_df.user_id == user_id].values[0][1:]\n",
    "    candidates_array = all_recommendations[all_recommendations.UserId == user_id][['ItemId', 'prediction']].values\n",
    "    candidates = {item: score for item, score in candidates_array}\n",
    "    \n",
    "    scores = [\n",
    "        candidates.get(item, 1e-8) if item in candidates else 1e-8\n",
    "        for item in item_names\n",
    "    ]\n",
    "    \n",
    "    # Sort items based on score in descending order\n",
    "    sorted_list = sorted(zip(item_names, scores), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    preds.append([user_id] + [i[0] for i in sorted_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afc7919-24cb-42e8-9b94-7e7c696d69f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(preds).to_csv(f'{out_path}/predict_SAR.csv', index = False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d8faa0-3fbb-4cf9-b9a9-89c08afb0864",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Ensemble Phase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f62f83-3c21-4d25-a5c7-a726cbf932c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!/opt/conda/envs/rapids-24.10/bin/ipython Rerank.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28c99dd-2071-4eb8-95d1-00b027acebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp $pwd/runs/reranking/predict.csv $out_path/predict_RRK.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e901fe5-a444-4df7-b7af-fe3db49d4464",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1 = pd.read_csv(f'{out_path}/XSimGCL_predict.csv', names = ['user_id'] + [f'item_id_{i}' for i in range(1,1001)])\n",
    "sub2 = pd.read_csv(f'{out_path}/RecVAE_predict.csv', names = ['user_id'] + [f'item_id_{i}' for i in range(1,1001)])\n",
    "sub3 = pd.read_csv(f'{out_path}/SimGCL_predict.csv', names = ['user_id'] + [f'item_id_{i}' for i in range(1,1001)])\n",
    "sub4 = pd.read_csv(f'{out_path}/LightGCN_predict.csv', names = ['user_id'] + [f'item_id_{i}' for i in range(1,1001)])\n",
    "sub5 = pd.read_csv(f'{out_path}/DirectAU_predict.csv', names = ['user_id'] + [f'item_id_{i}' for i in range(1,1001)])\n",
    "sub6 = pd.read_csv(f'{out_path}/ALS_predict.csv', names = ['user_id'] + [f'item_id_{i}' for i in range(1,1001)])\n",
    "sub7 = pd.read_csv(f'{out_path}/SAR_predict.csv', names = ['user_id'] + [f'item_id_{i}' for i in range(1,1001)])\n",
    "\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub['user_id'] = sub1['user_id']\n",
    "sub1['prediction0'] = sub1.apply(lambda row: ' '.join(str(row[f'item_id_{i+1}']) for i in range(1000)), axis=1)\n",
    "sub2['prediction1'] = sub2.apply(lambda row: ' '.join(str(row[f'item_id_{i+1}']) for i in range(1000)), axis=1)\n",
    "sub3['prediction2'] = sub3.apply(lambda row: ' '.join(str(row[f'item_id_{i+1}']) for i in range(1000)), axis=1)\n",
    "sub4['prediction3'] = sub4.apply(lambda row: ' '.join(str(row[f'item_id_{i+1}']) for i in range(1000)), axis=1)\n",
    "sub5['prediction4'] = sub5.apply(lambda row: ' '.join(str(row[f'item_id_{i+1}']) for i in range(1000)), axis=1)\n",
    "sub6['prediction5'] = sub6.apply(lambda row: ' '.join(str(row[f'item_id_{i+1}']) for i in range(1000)), axis=1)\n",
    "sub7['prediction6'] = sub7.apply(lambda row: ' '.join(str(row[f'item_id_{i+1}']) for i in range(1000)), axis=1)\n",
    "\n",
    "\n",
    "sub['prediction0'] = sub1['prediction0']\n",
    "sub['prediction1'] = sub2['prediction1']\n",
    "sub['prediction2'] = sub3['prediction2']\n",
    "sub['prediction3'] = sub4['prediction3']\n",
    "sub['prediction4'] = sub5['prediction4']\n",
    "sub['prediction5'] = sub6['prediction5']\n",
    "sub['prediction6'] = sub7['prediction6']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5efce71-e3d8-431e-af8f-b124b6eb4ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble dựa trên RRF\n",
    "def cust_blend(dt, W = [2, 2, 1.2, 1.5, 1.5, 1, 1]):\n",
    "    #Global ensemble weights\n",
    "    #W = [1.15,0.95,0.85]\n",
    "    \n",
    "    #Create a list of all model predictions\n",
    "    REC = []\n",
    "    REC.append(dt['prediction0'].split())\n",
    "    REC.append(dt['prediction1'].split())\n",
    "    REC.append(dt['prediction2'].split())\n",
    "    REC.append(dt['prediction3'].split())\n",
    "    REC.append(dt['prediction4'].split())\n",
    "    REC.append(dt['prediction5'].split())\n",
    "    REC.append(dt['prediction6'].split())\n",
    "    REC.append(dt['prediction7'].split())\n",
    "    REC.append(dt['prediction8'].split())   \n",
    "\n",
    "    #Create a dictionary of items recommended. \n",
    "    #Assign a weight according the order of appearance and multiply by global weights\n",
    "    res = {}\n",
    "    for M in range(len(REC)):\n",
    "        for n, v in enumerate(REC[M]):\n",
    "            if v in res:\n",
    "                res[v] += (W[M]/(n+1))\n",
    "            else:\n",
    "                res[v] = (W[M]/(n+1))\n",
    "    \n",
    "    # Sort dictionary by item weights\n",
    "    res = list(dict(sorted(res.items(), key=lambda item: -item[1])).keys())\n",
    "    \n",
    "    # Return the top 12 itens only\n",
    "    return ' '.join(res[:1000])\n",
    "\n",
    "sub['prediction'] = sub.apply(lambda x: cust_blend(x), axis=1)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5df1df1-9e8d-48f1-ba83-fc25b89ec3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = sub[['user_id', 'prediction']]\n",
    "value_lists = sub['prediction'].str.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9646e260-509c-4d7c-a70b-99e32b286b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.DataFrame(value_lists.tolist(), index=sub['user_id']).reset_index()\n",
    "final.to_csv(f'{out_path}/predict_ensemble_7_file.csv', index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac3dc40-7f45-4bf1-9bff-42a19f84a21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp $out_path/predict_ensemble_7_file.csv $pwd/submission/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2827248f-fcda-4f98-bb23-04664d327963",
   "metadata": {},
   "source": [
    "# Co-Visitation-Matrix"
   ]
  },
  {
   "cell_type": "raw",
   "id": "01aad077-d8ce-41da-a399-8602c2a0a86b",
   "metadata": {},
   "source": [
    "!/opt/conda/envs/rapids-24.10/bin/ipython Co-Visitation-Matrix.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396d7782-8721-4740-8aef-a6e192f5fa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp $pwd/runs/co-visitation-matrix/predict.csv $out_path/predict_CVM.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c90a230-fc11-46ac-90ab-7dd9b3e6c840",
   "metadata": {},
   "source": [
    "# ReRanking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177dd13b-c1e1-424a-a351-8a72c8d4b844",
   "metadata": {},
   "outputs": [],
   "source": [
    "!/opt/conda/envs/rapids-24.10/bin/ipython Rerank.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3e3059-fd37-46bc-af2d-41feb7814d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp $pwd/runs/reranking/predict.csv $out_path/predict_RRK.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696901dc-a7f3-44ad-8d8f-884394a51524",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Get Low Agreement user and User Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae4e024-1bfb-4b89-8da1-eb1e22d78547",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Low Agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c061766-81b3-47c4-bc42-1efa4b0799d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "recvae = pd.read_csv(f\"{out_path}/RecVAE_predict.csv\", header=None)\n",
    "als = pd.read_csv(f\"{out_path}/ALS_predict.csv\", header=None)\n",
    "lightgcn = pd.read_csv(f\"{out_path}/LightGCN_predict.csv\", header=None)\n",
    "sar = pd.read_csv(f\"{out_path}/SAR_predict.csv\", header=None)\n",
    "xsimgcl = pd.read_csv(f\"{out_path}/XSimGCL_predict.csv\", header=None)\n",
    "directau = pd.read_csv(f\"{out_path}/DirectAU_predict.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa33b28-aa0f-4582-8405-688408937c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{outpat}/predict_ensemble_7file.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dace5b99-9407-4c78-bb04-66e0dfa2845b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def load_and_process_recommendations(file_paths):\n",
    "    \"\"\"\n",
    "    Đọc và xử lý các file khuyến nghị từ nhiều mô hình\n",
    "    \"\"\"\n",
    "    model_predictions = {}\n",
    "    for model_name, file_path in file_paths.items():\n",
    "        df = pd.read_csv(file_path, header=None)[[0,1,2,3]]\n",
    "        # Chuyển đổi DataFrame thành dictionary với key là user_id và value là list các khuyến nghị\n",
    "        predictions = {str(row[0]): list(row[1:]) for _, row in df.iterrows()}\n",
    "        model_predictions[model_name] = predictions\n",
    "    return model_predictions\n",
    "\n",
    "def calculate_jaccard_similarity(set1, set2):\n",
    "    \"\"\"\n",
    "    Tính toán độ tương đồng Jaccard giữa hai tập hợp\n",
    "    \"\"\"\n",
    "    intersection = len(set(set1) & set(set2))\n",
    "    union = len(set(set1) | set(set2))\n",
    "    return intersection / union if union != 0 else 0\n",
    "\n",
    "def analyze_model_agreement(model_predictions):\n",
    "    \"\"\"\n",
    "    Phân tích độ đồng thuận giữa các mô hình\n",
    "    \"\"\"\n",
    "    user_similarities = defaultdict(list)\n",
    "    model_names = list(model_predictions.keys())\n",
    "    \n",
    "    # Với mỗi người dùng, tính toán độ tương đồng giữa các cặp mô hình\n",
    "    for user_id in model_predictions[model_names[0]].keys():\n",
    "        similarities = []\n",
    "        # So sánh từng cặp mô hình\n",
    "        for i in range(len(model_names)):\n",
    "            for j in range(i+1, len(model_names)):\n",
    "                model1, model2 = model_names[i], model_names[j]\n",
    "                recs1 = model_predictions[model1][user_id]\n",
    "                recs2 = model_predictions[model2][user_id]\n",
    "                similarity = calculate_jaccard_similarity(recs1, recs2)\n",
    "                similarities.append(similarity)\n",
    "        \n",
    "        # Tính trung bình độ tương đồng cho người dùng này\n",
    "        avg_similarity = np.mean(similarities)\n",
    "        user_similarities[user_id] = avg_similarity\n",
    "    \n",
    "    return user_similarities\n",
    "\n",
    "def get_extreme_cases(user_similarities, threshold_high=0.5, threshold_low=0.15 ):\n",
    "    \"\"\"\n",
    "    Lấy ra các trường hợp có độ đồng thuận cao và thấp\n",
    "    \"\"\"\n",
    "    high_agreement = {k: v for k, v in user_similarities.items() if v >= threshold_high}\n",
    "    low_agreement = {k: v for k, v in user_similarities.items() if v <= threshold_low}\n",
    "    \n",
    "    return high_agreement, low_agreement\n",
    "\n",
    "def analyze_recommendations():\n",
    "    # Định nghĩa đường dẫn đến các file\n",
    "    file_paths = {\n",
    "        'RecVAE': f\"{out_path}/RecVAE_predict.csv\",\n",
    "        'ALS': f\"{out_path}/ALS_predict.csv\",\n",
    "        'LightGCN': f\"{out_path}/LightGCN_predict.csv\",\n",
    "        'SAR': f\"{out_path}/SAR_predict.csv\",\n",
    "        'XSimGCL': f\"{out_path}/XSimGCL_predict.csv\"\n",
    "    }\n",
    "    \n",
    "    # Đọc và xử lý dữ liệu\n",
    "    model_predictions = load_and_process_recommendations(file_paths)\n",
    "    \n",
    "    # Phân tích độ đồng thuận\n",
    "    user_similarities = analyze_model_agreement(model_predictions)\n",
    "    \n",
    "    # Lấy ra các trường hợp đặc biệt\n",
    "    high_agreement, low_agreement = get_extreme_cases(user_similarities)\n",
    "    \n",
    "    # In kết quả phân tích\n",
    "    print(f\"Tổng số người dùng: {len(user_similarities)}\")\n",
    "    print(f\"Số người dùng có độ đồng thuận cao: {len(high_agreement)}\")\n",
    "    print(f\"Số người dùng có độ đồng thuận thấp: {len(low_agreement)}\")\n",
    "    \n",
    "    # In ra một vài ví dụ\n",
    "    print(\"\\nVí dụ về người dùng có độ đồng thuận cao:\")\n",
    "    for user_id, similarity in list(high_agreement.items())[:5]:\n",
    "        print(f\"User {user_id}: {similarity:.3f}\")\n",
    "        \n",
    "    print(\"\\nVí dụ về người dùng có độ đồng thuận thấp:\")\n",
    "    for user_id, similarity in list(low_agreement.items())[:5]:\n",
    "        print(f\"User {user_id}: {similarity:.3f}\")\n",
    "        \n",
    "    return high_agreement, low_agreement, user_similarities\n",
    "\n",
    "# Chạy phân tích\n",
    "high_agreement, low_agreement, user_similarities = analyze_recommendations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cb268e-18c7-4332-a660-1508d70353e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_agreement_user = low_agreement.keys()\n",
    "\n",
    "with open(f\"{out_path}/low_agreement_user.txt\", \"w\") as f:\n",
    "    for key in low_agreement_user:\n",
    "        f.write(key + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b5c6fc-1525-48b3-9b1a-ca57e92b3370",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## New Item with Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8852430-423c-4590-b86d-bc4448b15d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1f9839-8682-4b53-8eb7-7d1104814461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE  # You can also use UMAP from cuML or sklearn\n",
    "import plotly.express as px\n",
    "\n",
    "# Load the user embeddings\n",
    "embedding_file_path = 'runs/lightgcn/user_embedding.pkl'\n",
    "\n",
    "with open(embedding_file_path, 'rb') as f:\n",
    "    user_embeddings = pickle.load(f)\n",
    "\n",
    "# Convert the embeddings into a NumPy array (make sure it's in the right shape)\n",
    "embedding_matrix = np.array(list(user_embeddings.values()))\n",
    "\n",
    "# Dimensionality Reduction using t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, init='pca', metric='euclidean', method=\"barnes_hut\")\n",
    "X_tsne = tsne.fit_transform(embedding_matrix)\n",
    "\n",
    "# Optional: Get the t-SNE divergence (useful for diagnostic purposes)\n",
    "print(f\"t-SNE KL Divergence: {tsne.kl_divergence_}\")\n",
    "\n",
    "# Visualize the results using Plotly\n",
    "# Create a DataFrame for easy plotting\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(X_tsne, columns=[\"TSNE Component 1\", \"TSNE Component 2\"])\n",
    "\n",
    "# If you have any labels (e.g., cluster IDs or user types), you can add them to the DataFrame\n",
    "# Example: df['Cluster'] = cluster_labels  # If you have cluster labels\n",
    "\n",
    "# Create the Plotly scatter plot\n",
    "fig = px.scatter(df, x=\"TSNE Component 1\", y=\"TSNE Component 2\",\n",
    "                 title=\"User Latent Space (t-SNE)\",\n",
    "                 labels={\"TSNE Component 1\": \"Dimension 1\", \"TSNE Component 2\": \"Dimension 2\"},\n",
    "                 template=\"plotly_dark\")  # Optional: use dark theme\n",
    "\n",
    "# Update layout for better readability\n",
    "fig.update_layout(\n",
    "    title=\"User Latent Space\",\n",
    "    xaxis_title=\"t-SNE Component 1\",\n",
    "    yaxis_title=\"t-SNE Component 2\",\n",
    "    showlegend=False  # Set to True if you want to display legends (e.g., for clusters)\n",
    ")\n",
    "\n",
    "# Show the interactive plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581aac3d-6bc9-4d07-8059-f2dc9f406fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Compute the k-nearest neighbors distances\n",
    "min_samples = 5  # Typically, this is a small integer, like 5 or 10\n",
    "neighbors = NearestNeighbors(n_neighbors=min_samples)\n",
    "neighbors_fit = neighbors.fit(X_tsne)  # Use your 2D reduced data (e.g., t-SNE embeddings)\n",
    "distances, indices = neighbors_fit.kneighbors(X_tsne)\n",
    "\n",
    "# Sort the distances\n",
    "distances = np.sort(distances[:, min_samples-1], axis=0)\n",
    "\n",
    "# Plot the k-distance graph (elbow method)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(distances)\n",
    "plt.title(f'k-distance Graph (k={min_samples})')\n",
    "plt.xlabel('Data points sorted by distance to k-th neighbor')\n",
    "plt.ylabel(f'{min_samples}-th Nearest Neighbor Distance')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc8ab8e-d03d-4122-9747-6c8cc2a5cf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=1.9, min_samples=5, metric='euclidean')  # You may need to adjust these hyperparameters\n",
    "cluster_labels = dbscan.fit_predict(X_tsne)\n",
    "\n",
    "# Add cluster labels to the DataFrame\n",
    "df = pd.DataFrame(X_tsne, columns=[\"TSNE Component 1\", \"TSNE Component 2\"])\n",
    "df['Cluster'] = cluster_labels\n",
    "\n",
    "# Visualize the result using Plotly\n",
    "fig = px.scatter(df, x=\"TSNE Component 1\", y=\"TSNE Component 2\", color=\"Cluster\",\n",
    "                 title=\"User Latent Space with DBSCAN Clusters\",\n",
    "                 labels={\"TSNE Component 1\": \"Dimension 1\", \"TSNE Component 2\": \"Dimension 2\"},\n",
    "                 template=\"plotly_dark\")  # Optional: use \"plotly_dark\" or other templates\n",
    "\n",
    "# Update layout for better readability\n",
    "fig.update_layout(\n",
    "    title=\"User Latent Space (DBSCAN Clusters)\",\n",
    "    xaxis_title=\"t-SNE Component 1\",\n",
    "    yaxis_title=\"t-SNE Component 2\",\n",
    "    showlegend=True  # Show the legend to display the cluster colors\n",
    ")\n",
    "\n",
    "# Show the interactive plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567722d6-3c66-40b0-8b45-15b9d8f2af26",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = list(user_embeddings.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c857138-4480-4023-a7c8-a320d0308a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('runs/lightgcn/user_clusters.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bc9ce7-a787-4f2c-9953-9c530d638c16",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Append New Item by Cluster and Low Agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b60485-f3ac-44d6-a28d-6cb84e3547a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = pd.read_csv('runs/lightgcn/user_clusters.csv')\n",
    "cluster.head()\n",
    "\n",
    "user_df = test.copy()\n",
    "user_df = user_df.set_index('user_id')\n",
    "cluster = cluster.set_index('User ID')\n",
    "user_df = user_df.join(cluster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59f6498-13f2-4ad5-bd83-7323cf7f3070",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def get_most_common_items_for_cluster(user_df, cluster_column='Cluster', item_columns=None):\n",
    "    cluster_item_counts = {}\n",
    "\n",
    "    # Iterate over each cluster\n",
    "    for cluster in user_df[cluster_column].unique():\n",
    "        # Get users in this cluster\n",
    "        cluster_users = user_df[user_df[cluster_column] == cluster]\n",
    "        \n",
    "        # Get all item interactions for these users\n",
    "        cluster_items = cluster_users[item_columns].values.flatten()\n",
    "        \n",
    "        # Count the frequency of each item (ignore NaN or empty interactions)\n",
    "        cluster_items = [item for item in cluster_items if pd.notna(item)]\n",
    "        item_counter = Counter(cluster_items)\n",
    "        \n",
    "        # Save the most common items in this cluster\n",
    "        cluster_item_counts[cluster] = item_counter.most_common()\n",
    "    \n",
    "    return cluster_item_counts\n",
    "\n",
    "item_columns = [f'item_id_{i+1}' for i in range(1000)] \n",
    "cluster_item_counts = get_most_common_items_for_cluster(user_df, item_columns=item_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c08afd0-2751-402f-9903-08996b0d9407",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/training_set.csv\")\n",
    "list_all_train_item = train[\"ItemId\"].unique()\n",
    "items_df = test[item_columns]\n",
    "all_test_items = items_df.values.flatten()\n",
    "all_test_items = set(all_test_items)\n",
    "old_items = set(all_test_items).intersection(set(list_all_train_item))\n",
    "new_items = all_test_items - old_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56edc9d-abd0-49c5-a281-c867ac2d1d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_items_dict = {}\n",
    "\n",
    "for user_idx, user_id in enumerate(test[\"user_id\"]):  # Assuming 'user_id' is the first column\n",
    "    # Get the list of items the user has interacted with\n",
    "    user_items = items_df.iloc[user_idx].values.tolist()\n",
    "    \n",
    "    # Filter out items that are NaN or empty\n",
    "    user_items = [item for item in user_items if pd.notna(item) and item != '']\n",
    "    \n",
    "    # Find new items by checking which of the user's items are in `new_items`\n",
    "    user_new_items = [item for item in user_items if item in new_items]\n",
    "    \n",
    "    # Add to the dictionary: user_id -> list of new items\n",
    "    new_items_dict[user_id] = user_new_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559c3e87-04cb-44ad-ab14-e7d9131e6508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_items_for_user(user_id, cluster_item_counts, new_items_dict, user_df, item_columns, top_n=1000):\n",
    "    # Get the user's cluster\n",
    "    user_cluster = user_df.loc[user_id, 'Cluster']\n",
    "    # Get the most common items in this cluster\n",
    "    common_items = [(item, count) for item, count in cluster_item_counts[user_cluster]]\n",
    "    common_items = pd.DataFrame(common_items, columns=['item_id', 'count'])\n",
    "   \n",
    "    # Get the new items for this user\n",
    "    new_items = new_items_dict.get(user_id, [])\n",
    "    recommended_items = common_items[common_items['item_id'].isin(new_items)]\n",
    "    # print(recommended_items)\n",
    "    recommended_items = recommended_items.sort_values(by='count', ascending=False)['item_id'].tolist()\n",
    "    # Ensure the recommended list has 1000 items (pad with \"empty\" items if necessary)\n",
    "    recommended_items += [\"0\"] * (top_n - len(recommended_items))  # Pad with empty strings\n",
    "    # print(recommended_items)\n",
    "    return recommended_items\n",
    "\n",
    "# Create a list to hold all recommendations\n",
    "recommendations = []\n",
    "\n",
    "# Generate recommendations for each user\n",
    "for user_id in user_df.index:\n",
    "    recommended_items = recommend_items_for_user(user_id, cluster_item_counts, new_items_dict, user_df, item_columns)\n",
    "    recommendations.append([user_id] + recommended_items)\n",
    "# Convert the recommendations into a DataFrame\n",
    "recommendations_df = pd.DataFrame(recommendations, columns=['user_id'] + [f'item_{i+1}' for i in range(1000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63911b93-0008-4f20-8d9c-8e276819c55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "last_1000_columns = recommendations_df.iloc[:, -1000:]\n",
    "\n",
    "# Count rows where there is at least one non-zero value in the last 1000 columns\n",
    "non_zero_rows = (last_1000_columns != \"0\").any(axis=1)\n",
    "\n",
    "# Count the number of such rows\n",
    "count_non_zero_rows = non_zero_rows.sum()\n",
    "\n",
    "print(\"Number of rows with non-zero values in the last 1000 columns:\", count_non_zero_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dccded-09ce-4111-a040-d5417c08c270",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations_df.to_csv('submission/predict_new.csv', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fcba0e-4754-43af-88de-98837ab3b31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = pd.read_csv(f'{out_path}/LightGCN_predict.csv', names=['user_id'] + [f'item_id_{i}' for i in range(1,1001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c861eb-2094-4b8b-a120-ec06d8f33a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read keys from a file into a list\n",
    "with open(f\"{out_path}/low_agreement_user.txt\", \"r\") as f:\n",
    "    keys = [line.strip() for line in f.readlines()]\n",
    "len(keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2abe71-7e42-4c52-9631-d5d73cf7f138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best.loc[recommendations_df['item_1'] != \"0\", 'item_id_10'] = recommendations_df['item_1']\n",
    "count = 0\n",
    "for idx, row in best.iterrows():\n",
    "    if row['user_id'] in keys:\n",
    "        # Get the corresponding recommendation for this user\n",
    "        recommendation = recommendations_df.loc[recommendations_df['user_id'] == row['user_id'], 'item_1'].values\n",
    "        \n",
    "        if recommendation and recommendation[0] != '0':  # Check if the recommendation is not '0'\n",
    "            count += 1\n",
    "        #     for i in range(9, 4, -1):  # Start from item_id_9 and shift down to item_id_2\n",
    "        #         best.loc[idx, f'item_id_{i+1}'] = best.loc[idx, f'item_id_{i}']\n",
    "            # Replace item_id_1 with item_1 from recommendations_df\n",
    "            best.loc[idx, 'item_id_10'] = recommendation[0]\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a653d0f-3c05-40b4-9fc9-ab5b7d176611",
   "metadata": {},
   "outputs": [],
   "source": [
    "best.to_csv(f'out_path}/LightGCN_new_cluster_top10.csv', header=None, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f48709-defd-4ddc-9222-6559f08966c7",
   "metadata": {},
   "source": [
    "\n",
    "# Ensemble Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de2efe9-2800-4a80-92df-ffaca1c04367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0a9914-1052-4789-ad96-6b668a6226e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1 = pd.read_csv(f'{out_path}/predict_XSimGCL.csv', names = ['user_id'] + [f'item_id_{i}' for i in range(1,1001)])\n",
    "sub2 = pd.read_csv(f'{out_path}/predict_RecVAE.csv', names = ['user_id'] + [f'item_id_{i}' for i in range(1,1001)])\n",
    "sub3 = pd.read_csv(f'{out_path}/predict_SimGCL.csv', names = ['user_id'] + [f'item_id_{i}' for i in range(1,1001)])\n",
    "sub4 = pd.read_csv(f'{out_path}/LightGCN_new_cluster_top10.csv', names = ['user_id'] + [f'item_id_{i}' for i in range(1,1001)])\n",
    "sub5 = pd.read_csv(f'{out_path}/predict_DirectAU.csv', names = ['user_id'] + [f'item_id_{i}' for i in range(1,1001)])\n",
    "sub6 = pd.read_csv(f'{out_path}/predict_ALS.csv', names = ['user_id'] + [f'item_id_{i}' for i in range(1,1001)])\n",
    "sub7 = pd.read_csv(f'{out_path}/predict_SAR.csv', names = ['user_id'] + [f'item_id_{i}' for i in range(1,1001)])\n",
    "sub8 = pd.read_csv(f'{out_path}/predict_RRK.csv', names = ['user_id'] + [f'item_id_{i}' for i in range(1,1001)])\n",
    "sub9 = pd.read_csv(f'{out_path}/predict_ensemble_7file.csv', names = ['user_id'] + [f'item_id_{i}' for i in range(1,1001)])\n",
    "\n",
    "# sub1 = pd.read_csv(f'runs/private-test-attempt/predict_XSim_ensemble_noscore.csv', names = ['user_id'] + [f'item_id_{i}' for i in range(1,1001)])\n",
    "# sub2 = pd.read_csv(f'runs/private-test-attempt/RecVAE_05981.csv', names = ['user_id'] + [f'item_id_{i}' for i in range(1,1001)])\n",
    "# sub3 = pd.read_csv(f'runs/private-test-attempt/SimGCL_predict.csv', names = ['user_id'] + [f'item_id_{i}' for i in range(1,1001)])\n",
    "# sub4 = pd.read_csv(f'runs/private-test-attempt/LightGCN_new_cluster_top10.csv', names = ['user_id'] + [f'item_id_{i}' for i in range(1,1001)])\n",
    "# sub5 = pd.read_csv(f'runs/private-test-attempt/DirectAU_predict.csv', names = ['user_id'] + [f'item_id_{i}' for i in range(1,1001)])\n",
    "# sub6 = pd.read_csv(f'runs/private-test-attempt/ALS_new_cluster_top10.csv', names = ['user_id'] + [f'item_id_{i}' for i in range(1,1001)])\n",
    "# sub7 = pd.read_csv(f'runs/private-test-attempt/SAR_std_data.csv', names = ['user_id'] + [f'item_id_{i}' for i in range(1,1001)])\n",
    "# sub8 = pd.read_csv(f'runs/private-test-attempt/predict_full_rerank.csv', names = ['user_id'] + [f'item_id_{i}' for i in range(1,1001)])\n",
    "# sub9 = pd.read_csv(f'runs/private-test-attempt/predict_ensemble_8file.csv', names = ['user_id'] + [f'item_id_{i}' for i in range(1,1001)])\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub['user_id'] = sub1['user_id']\n",
    "sub1['prediction0'] = sub1.apply(lambda row: ' '.join(str(row[f'item_id_{i+1}']) for i in range(1000)), axis=1)\n",
    "sub2['prediction1'] = sub2.apply(lambda row: ' '.join(str(row[f'item_id_{i+1}']) for i in range(1000)), axis=1)\n",
    "sub3['prediction2'] = sub3.apply(lambda row: ' '.join(str(row[f'item_id_{i+1}']) for i in range(1000)), axis=1)\n",
    "sub4['prediction3'] = sub4.apply(lambda row: ' '.join(str(row[f'item_id_{i+1}']) for i in range(1000)), axis=1)\n",
    "sub5['prediction4'] = sub5.apply(lambda row: ' '.join(str(row[f'item_id_{i+1}']) for i in range(1000)), axis=1)\n",
    "sub6['prediction5'] = sub6.apply(lambda row: ' '.join(str(row[f'item_id_{i+1}']) for i in range(1000)), axis=1)\n",
    "sub7['prediction6'] = sub7.apply(lambda row: ' '.join(str(row[f'item_id_{i+1}']) for i in range(1000)), axis=1)\n",
    "sub8['prediction7'] = sub8.apply(lambda row: ' '.join(str(row[f'item_id_{i+1}']) for i in range(1000)), axis=1)\n",
    "sub9['prediction8'] = sub9.apply(lambda row: ' '.join(str(row[f'item_id_{i+1}']) for i in range(1000)), axis=1)\n",
    "\n",
    "\n",
    "sub['prediction0'] = sub1['prediction0']\n",
    "sub['prediction1'] = sub2['prediction1']\n",
    "sub['prediction2'] = sub3['prediction2']\n",
    "sub['prediction3'] = sub4['prediction3']\n",
    "sub['prediction4'] = sub5['prediction4']\n",
    "sub['prediction5'] = sub6['prediction5']\n",
    "sub['prediction6'] = sub7['prediction6']\n",
    "sub['prediction7'] = sub8['prediction7']\n",
    "sub['prediction8'] = sub9['prediction8']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4d0bed-2625-4150-aa66-b2e80770378e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble dựa trên RRF\n",
    "def cust_blend(dt, W = [2, 2, 1.2, 1.5, 1.5, 1, 1, 1, 2]):\n",
    "    #Global ensemble weights\n",
    "    #W = [1.15,0.95,0.85]\n",
    "    \n",
    "    #Create a list of all model predictions\n",
    "    REC = []\n",
    "    REC.append(dt['prediction0'].split())\n",
    "    REC.append(dt['prediction1'].split())\n",
    "    REC.append(dt['prediction2'].split())\n",
    "    REC.append(dt['prediction3'].split())\n",
    "    REC.append(dt['prediction4'].split())\n",
    "    REC.append(dt['prediction5'].split())\n",
    "    REC.append(dt['prediction6'].split())\n",
    "    REC.append(dt['prediction7'].split())\n",
    "    REC.append(dt['prediction8'].split())     \n",
    "\n",
    "    #Create a dictionary of items recommended. \n",
    "    #Assign a weight according the order of appearance and multiply by global weights\n",
    "    res = {}\n",
    "    for M in range(len(REC)):\n",
    "        for n, v in enumerate(REC[M]):\n",
    "            if v in res:\n",
    "                res[v] += (W[M]/(n+1))\n",
    "            else:\n",
    "                res[v] = (W[M]/(n+1))\n",
    "    \n",
    "    # Sort dictionary by item weights\n",
    "    res = list(dict(sorted(res.items(), key=lambda item: -item[1])).keys())\n",
    "    \n",
    "    # Return the top 12 itens only\n",
    "    return ' '.join(res[:1000])\n",
    "\n",
    "sub['prediction'] = sub.apply(lambda x: cust_blend(x), axis=1)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117f4735-3325-4b72-998b-fa73141fbf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = sub[['user_id', 'prediction']]\n",
    "value_lists = sub['prediction'].str.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3dcf3d-e352-4461-a675-57e921abebde",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.DataFrame(value_lists.tolist(), index=sub['user_id']).reset_index()\n",
    "final.to_csv('submission/predict.csv', index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf12f48-2ccc-4c36-86cb-fb3727c3d9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd submission && zip CHAMPION_FINAL_SUBMISSION.zip predict.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7710c3db-8b68-44dc-8178-851d870c1bb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapidsai",
   "language": "python",
   "name": "rapidsai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
