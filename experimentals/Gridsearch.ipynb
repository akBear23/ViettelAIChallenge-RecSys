{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b695d09c-6982-46df-9b58-2dd29f82c555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ItemId</th>\n",
       "      <th>Click</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75545</td>\n",
       "      <td>BYiR2R6HXg</td>\n",
       "      <td>mRhriA8HKP</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69937</td>\n",
       "      <td>4gqsMXs4ST</td>\n",
       "      <td>bAS10Ai3WN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>282940</td>\n",
       "      <td>NV1iw3vjY7</td>\n",
       "      <td>UPY8VgKAN0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18643</td>\n",
       "      <td>u1A8zZTCQR</td>\n",
       "      <td>LEEgNGikFR</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>171888</td>\n",
       "      <td>GZKapbpZ9D</td>\n",
       "      <td>qKwZIheE8N</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index      UserId      ItemId  Click  Purchase\n",
       "0   75545  BYiR2R6HXg  mRhriA8HKP      1         0\n",
       "1   69937  4gqsMXs4ST  bAS10Ai3WN      1         0\n",
       "2  282940  NV1iw3vjY7  UPY8VgKAN0      1         0\n",
       "3   18643  u1A8zZTCQR  LEEgNGikFR      1         0\n",
       "4  171888  GZKapbpZ9D  qKwZIheE8N      1         0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "test = pd.read_csv('data/test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0de93bdb-37bd-4f26-a800-3fc923f9dc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/viettel-ai-challenge-track-ds/SELFRec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd /workspace/viettel-ai-challenge-track-ds/SELFRec/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50207796-5d19-4452-b05c-a96c124680a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9618"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_items = test.groupby('UserId')['ItemId'].apply(list).to_dict()\n",
    "len(grouped_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "51d6251c-ea92-4bf8-9b10-3f1aeabf26e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((277638, 4), (14551, 4))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../data/training_set.csv')\n",
    "predict_df = pd.read_csv('../data/public_testset.csv', names=['user_id'] + [f'item_id_{i}' for i in range(1,1001)])\n",
    "test_user_id = predict_df['user_id'].values\n",
    "\n",
    "item_columns = predict_df.columns[1:]  # Lấy tất cả cột trừ cột uid\n",
    "item_in_test_df = pd.unique(predict_df[item_columns].values.ravel())\n",
    "#Lọc bỏ user_id bị lẫn trong tập test\n",
    "user_list = df.UserId.unique()\n",
    "item_in_test_df = list(set(item_in_test_df).difference(set(user_list)))\n",
    "\n",
    "test_df = df[~df.ItemId.isin(item_in_test_df)].sample(frac=0.05, random_state=42)  # 90% for train\n",
    "\n",
    "user_list = df.groupby('UserId')['ItemId'].nunique()\n",
    "user_list_denoise = user_list[(user_list<=20) & (user_list>=3)].index.to_list()\n",
    "final_user_list = []\n",
    "final_user_list.extend(user_list_denoise)\n",
    "final_user_list.extend(test_user_id)\n",
    "user_list_denoise = list(set(final_user_list))\n",
    "\n",
    "train_df = df.drop(test_df.index)\n",
    "train_df = train_df[train_df.UserId.isin(user_list_denoise)] # Remaining 10% for test\n",
    "\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cffc7634-15d6-4789-aada-12d75e444970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((375372, 4), (14551, 4))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# df = pd.read_csv('../data/training_set.csv')\n",
    "# predict_df = pd.read_csv('../data/test_set_private.csv', names=['user_id'] + [f'item_id_{i}' for i in range(1,1001)])\n",
    "# test_user_id = predict_df['user_id'].values\n",
    "\n",
    "# user_rated = df.groupby('UserId')['ItemId'].apply(list).to_dict()\n",
    "\n",
    "# item_columns = predict_df.columns[1:]  # Lấy tất cả cột trừ cột uid\n",
    "# item_in_test_df = pd.unique(predict_df[item_columns].values.ravel())\n",
    "# #Lọc bỏ user_id bị lẫn trong tập test\n",
    "# user_list = df.UserId.unique()\n",
    "# item_in_test_df = list(set(item_in_test_df).difference(set(user_list)))\n",
    "\n",
    "# tmp = df.groupby('UserId')['ItemId'].size().reset_index()\n",
    "# user_only_one_interact = tmp[tmp.ItemId <= 3].UserId.unique()\n",
    "\n",
    "# test_df = df[(~df.ItemId.isin(item_in_test_df))&(~df.UserId.isin(user_only_one_interact))].sample(frac=0.05, random_state=42)  # 90% for train\n",
    "# # train_df = df\n",
    "# train_df = df.drop(test_df.index)  # Remaining 10% for test\n",
    "\n",
    "# train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "30d8434e-1478-4902-9771-7bf4f811d073",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "38b1ad3a-c539-44cb-84da-5c8f0606684b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_test_id = test_df.UserId.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d958f90b-3bf3-4803-8c1a-2f60da725291",
   "metadata": {},
   "source": [
    "# Get preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b4f52b9e-90f1-444f-90a4-e4ceaffef5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.conf import ModelConf\n",
    "from data.loader import FileIO\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from base.graph_recommender import GraphRecommender\n",
    "# from util.conf import OptionConf\n",
    "from util.sampler import next_batch_pairwise\n",
    "from base.torch_interface import TorchGraphInterface\n",
    "from util.loss_torch import bpr_loss, l2_reg_loss, InfoNCE\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dacadec3-de95-4dc2-99dc-431dae57445c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "item_embedding_xsim = pd.read_pickle('../data/embeddings/emb_item_XSim_denoise.pickle')\n",
    "user_embedding_xsim = pd.read_pickle('../data/embeddings/emb_user_XSim_denoise.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb9ed44-985b-4ea6-83de-34ce606d7f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open(\"../data/grid_search/error_user.pkl\",'rb') as file:\n",
    "    error_user = pickle.load(file)\n",
    "error_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1f0ac0f6-53f1-42ab-9d27-2e7a01da357f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8655"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_test_id = [x for x in user_test_id if x not in error_user]\n",
    "len(user_test_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "22bc9217-d373-4f04-b6f0-66485f145ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_rated = train_df.groupby('UserId')['ItemId'].apply(list).to_dict()\n",
    "\n",
    "import torch\n",
    "user_emb = []\n",
    "user2id = {}\n",
    "cnt = 0\n",
    "user_list_xsim = []\n",
    "for user in user_embedding_xsim:\n",
    "    user_emb.append(user_embedding_xsim[user])\n",
    "    user_list_xsim.append(user)\n",
    "    user2id[user] = cnt\n",
    "    cnt+=1\n",
    "user_emb = torch.tensor(user_emb)\n",
    "\n",
    "item_emb = []\n",
    "item2id = {}\n",
    "id2item = {}\n",
    "cnt = 0\n",
    "item_list_xsim = []\n",
    "for item in item_embedding_xsim:\n",
    "    item_emb.append(item_embedding_xsim[item])\n",
    "    item_list_xsim.append(item)\n",
    "    item2id[item] = cnt\n",
    "    id2item[cnt] = item\n",
    "    cnt+=1\n",
    "item_emb = torch.tensor(item_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6df06234-2cef-480f-853f-27dd48fb88e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.algorithm import find_k_largest\n",
    "error_user = []\n",
    "def test():\n",
    "    def process_bar(num, total):\n",
    "        rate = float(num) / total\n",
    "        ratenum = int(50 * rate)\n",
    "        print(f'\\rProgress: [{\"+\" * ratenum}{\" \" * (50 - ratenum)}]{ratenum * 2}%', end='', flush=True)\n",
    "\n",
    "    rec_list = {}\n",
    "    user_count = len(user_test_id)\n",
    "    for i, user in enumerate(user_test_id):\n",
    "        try:\n",
    "            candidates = torch.matmul(torch.tensor(user_embedding_xsim[user]).cuda(), torch.tensor(item_emb.transpose(0, 1)).cuda()).cpu().numpy()\n",
    "            try: \n",
    "                rated_list = user_rated[user]\n",
    "            except:\n",
    "                rated_list = []\n",
    "            for item in rated_list:\n",
    "                try:\n",
    "                    candidates[item2id[item]] = -10e8\n",
    "                except:\n",
    "                    pass\n",
    "            ids, scores = find_k_largest(10, candidates)\n",
    "            item_names = [id2item[iid] for iid in ids]\n",
    "            rec_list[user] = list(zip(item_names, scores))\n",
    "        except:\n",
    "            error_user.append(user)\n",
    "        if i % 100 == 0:\n",
    "            process_bar(i, user_count)\n",
    "    process_bar(user_count, user_count)\n",
    "    print('')\n",
    "    return rec_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9846731d-2524-4381-9cbb-57d4abd852dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [                                                  ]0%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_239449/3024906971.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  candidates = torch.matmul(torch.tensor(user_embedding_xsim[user]).cuda(), torch.tensor(item_emb.transpose(0, 1)).cuda()).cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n"
     ]
    }
   ],
   "source": [
    "rec_list = test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d5bd577a-bb11-414e-8fcc-5e6a262c544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../data/grid_search/XSimDenoise.json\", \"w\") as file:\n",
    "    json.dump(rec_list, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0dfa8308-1792-4271-8ec5-15c4d0da77b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/grid_search/error_user.pkl\", \"wb\") as file:\n",
    "    pickle.dump(error_user, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ef00cc02-137c-47ed-8ab8-0145d1f7c9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9618\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/grid_search/XSimStandard.json\", \"r\") as file:\n",
    "    rec_list = json.load(file)\n",
    "    print(len(rec_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d14f23b9-abc2-4b17-af1b-2f64926b818c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for user_id in user_test_id:\n",
    "    data.append([user_id] + [i[0] for i in rec_list[user_id]])\n",
    "df1 = pd.DataFrame(data)\n",
    "df1.to_csv('../data/grid_search/predict_XSim_standard.csv', index = False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7ff007-1bb7-4d19-b2b2-68442884e41e",
   "metadata": {},
   "source": [
    "# Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "561dd40b-0028-4419-9b47-5f6aa599f888",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_dict = {}\n",
    "gt = set(zip(test_df['UserId'], test_df['ItemId']))\n",
    "for user_id, item_id in gt:\n",
    "    if user_id not in gt_dict:\n",
    "        gt_dict[user_id] = set()\n",
    "    gt_dict[user_id].add(item_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "35181933-54bb-4ba2-afc6-499b1a8aa9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt_dict['xfjV2OVaYk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "07a71c2a-e9df-4822-aba0-ffe9caf726e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ndcg_at_10(df, gt):\n",
    "    ndcg_total = 0\n",
    "    num_users = len(df)\n",
    "    \n",
    "    # Iterate through each user in the DataFrame\n",
    "    for _, row in df.iterrows():\n",
    "        user_id = row.iloc[0]  # user_id is in the first column\n",
    "        item_ids = row[1:].values  # recommended item_ids are the remaining columns\n",
    "        \n",
    "        # Get the ground truth relevant items for the current user\n",
    "        relevant_items = gt.get(user_id, set())\n",
    "        # print(relevant_items)\n",
    "        # Calculate DCG@10\n",
    "        dcg = 0\n",
    "        for i, item_id in enumerate(item_ids[:10]):  # Top 10 items\n",
    "            # print(item_id)\n",
    "            relevance = 1 if item_id in relevant_items else 0\n",
    "            dcg += relevance / np.log2(i + 2)  # log2(i+2) because index is 0-based\n",
    "        \n",
    "        # Calculate Ideal DCG@10 (IDCG) - assume the relevant items are in the top positions\n",
    "        ideal_item_ids = list(relevant_items)\n",
    "        idcg = 0\n",
    "        for i, item_id in enumerate(item_ids[:10]):  # Top 10 items\n",
    "            relevance = 1 if i < len(ideal_item_ids) else 0  # Relevance is 1 for the top relevant items\n",
    "            idcg += relevance / np.log2(i + 2)\n",
    "        \n",
    "        # NDCG is DCG divided by IDCG\n",
    "        ndcg = dcg / idcg if idcg > 0 else 0  # Prevent division by zero\n",
    "        # print(dcg, idcg)\n",
    "        ndcg_total += ndcg\n",
    "    # print(ndcg_total)\n",
    "    # Return the average NDCG\n",
    "    return ndcg_total / num_users if num_users > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "101d7565-72da-4209-97ec-d8f6ee34a6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def NDCG(origin,res,N):\n",
    "    sum_NDCG = 0\n",
    "    for user in res:\n",
    "        DCG = 0\n",
    "        IDCG = 0\n",
    "        #1 = related, 0 = unrelated\n",
    "        for n, item in enumerate(res[user]):\n",
    "            if item[0] in origin[user]:\n",
    "                DCG+= 1.0/math.log(n+2,2)\n",
    "        for n, item in enumerate(list(origin[user])[:N]):\n",
    "            IDCG+=1.0/math.log(n+2,2)\n",
    "        sum_NDCG += DCG / IDCG\n",
    "    return round(sum_NDCG / len(res),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "75996715-b568-4c1b-ac2b-abb9dacac764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/viettel-ai-challenge-track-ds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "defad4f4-909d-44fa-89d9-416b756ca89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('data/grid_search/predict_XSim_denoise.csv', names=['user_id'] + [f'item_id_{i}' for i in range(1,1001)])\n",
    "df2 = pd.read_csv('data/grid_search/predict_XSim_full.csv', names=['user_id'] + [f'item_id_{i}' for i in range(1,1001)])\n",
    "df3 = pd.read_csv('data/grid_search/predict_XSim_standard.csv', names=['user_id'] + [f'item_id_{i}' for i in range(1,1001)])\n",
    "df4 = pd.read_csv('runs/data_for_grid_search/DirectAU_predict.csv', names=['user_id'] + [f'item_id_{i}' for i in range(1,1001)])\n",
    "df5 = pd.read_csv('runs/data_for_grid_search/LightGCN_predict.csv', names=['user_id'] + [f'item_id_{i}' for i in range(1,1001)])\n",
    "df6 = pd.read_csv('data/grid_search/SimGCL_predict.csv', names = ['user_id', 'ItemId'])\n",
    "df7 = pd.read_csv('data/grid_search/predict_RecVAE.csv', names=['user_id', 'ItemId'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4dad77a2-45ce-4440-8a25-642aefffbc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def create_1000(df):\n",
    "    # Pad each list in the 'ItemId' column to ensure it has 1,000 items\n",
    "    padded_item_ids = df[\"ItemId\"].apply(lambda x: ast.literal_eval(x) + [0] * (1000 - len(ast.literal_eval(x))) if len(ast.literal_eval(x)) < 1000 else ast.literal_eval(x)[:1000])\n",
    "    \n",
    "    # Create a new DataFrame from the padded lists\n",
    "    expanded_df = pd.DataFrame(\n",
    "        padded_item_ids.to_list(), \n",
    "        columns=[f\"item_id_{i+1}\" for i in range(1000)]\n",
    "    )\n",
    "    \n",
    "    # Add the `user_id` back to the DataFrame\n",
    "    expanded_df.insert(0, \"user_id\", df[\"user_id\"])\n",
    "    \n",
    "    return expanded_df\n",
    "    \n",
    "df4 = create_1000(df4)\n",
    "df5 = create_1000(df5)\n",
    "df6 = create_1000(df6)\n",
    "df7 = create_1000(df7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "295b2fbf-8d18-40f5-a458-d46afd437c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id_1</th>\n",
       "      <th>item_id_2</th>\n",
       "      <th>item_id_3</th>\n",
       "      <th>item_id_4</th>\n",
       "      <th>item_id_5</th>\n",
       "      <th>item_id_6</th>\n",
       "      <th>item_id_7</th>\n",
       "      <th>item_id_8</th>\n",
       "      <th>item_id_9</th>\n",
       "      <th>...</th>\n",
       "      <th>item_id_991</th>\n",
       "      <th>item_id_992</th>\n",
       "      <th>item_id_993</th>\n",
       "      <th>item_id_994</th>\n",
       "      <th>item_id_995</th>\n",
       "      <th>item_id_996</th>\n",
       "      <th>item_id_997</th>\n",
       "      <th>item_id_998</th>\n",
       "      <th>item_id_999</th>\n",
       "      <th>item_id_1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BYiR2R6HXg</td>\n",
       "      <td>4TvzFK4vZj</td>\n",
       "      <td>5D0tcQNSPC</td>\n",
       "      <td>QsS2ZSeOHk</td>\n",
       "      <td>8IiY9QXFZd</td>\n",
       "      <td>SAT9ylfcTM</td>\n",
       "      <td>eCL613RYIJ</td>\n",
       "      <td>r4SIjbucnQ</td>\n",
       "      <td>EfrACUgZoC</td>\n",
       "      <td>8W8bbWrtd2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4gqsMXs4ST</td>\n",
       "      <td>bAS10Ai3WN</td>\n",
       "      <td>mGyqHKmCgE</td>\n",
       "      <td>3zHJo1yM3P</td>\n",
       "      <td>7Zk980ZEfp</td>\n",
       "      <td>teulFeLH2w</td>\n",
       "      <td>relvQBwWKb</td>\n",
       "      <td>NHdqdVNPAG</td>\n",
       "      <td>umAcyR4ruF</td>\n",
       "      <td>tuL0CRXFN7</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NV1iw3vjY7</td>\n",
       "      <td>umFzH7COE9</td>\n",
       "      <td>mqBGE4V7X4</td>\n",
       "      <td>Ryheh0wJqW</td>\n",
       "      <td>1w2tBAZklP</td>\n",
       "      <td>1YWZ7ysFBj</td>\n",
       "      <td>LvoCoE37bj</td>\n",
       "      <td>B1RAz6j2wo</td>\n",
       "      <td>rikHZfesKt</td>\n",
       "      <td>SEruLWaiyW</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u1A8zZTCQR</td>\n",
       "      <td>2Z1kYPx6P9</td>\n",
       "      <td>T5Fl5JjMdu</td>\n",
       "      <td>MZTnWwO0KP</td>\n",
       "      <td>vQ4LdEnMYd</td>\n",
       "      <td>D9BCAKYT2X</td>\n",
       "      <td>iqis3H2tXL</td>\n",
       "      <td>gDsbAt7Hpr</td>\n",
       "      <td>akr2wUs0GU</td>\n",
       "      <td>4iIvzaIZaZ</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GZKapbpZ9D</td>\n",
       "      <td>OPnJ3bzTjf</td>\n",
       "      <td>g0sLjzBbdC</td>\n",
       "      <td>YhXF0wLsfa</td>\n",
       "      <td>mKg9vRmHNo</td>\n",
       "      <td>90T0MJu0DH</td>\n",
       "      <td>1mHzIaSLoz</td>\n",
       "      <td>P4qcBEBhJJ</td>\n",
       "      <td>ZX3Pbjwi0s</td>\n",
       "      <td>DFhmb9OynU</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id   item_id_1   item_id_2   item_id_3   item_id_4   item_id_5  \\\n",
       "0  BYiR2R6HXg  4TvzFK4vZj  5D0tcQNSPC  QsS2ZSeOHk  8IiY9QXFZd  SAT9ylfcTM   \n",
       "1  4gqsMXs4ST  bAS10Ai3WN  mGyqHKmCgE  3zHJo1yM3P  7Zk980ZEfp  teulFeLH2w   \n",
       "2  NV1iw3vjY7  umFzH7COE9  mqBGE4V7X4  Ryheh0wJqW  1w2tBAZklP  1YWZ7ysFBj   \n",
       "3  u1A8zZTCQR  2Z1kYPx6P9  T5Fl5JjMdu  MZTnWwO0KP  vQ4LdEnMYd  D9BCAKYT2X   \n",
       "4  GZKapbpZ9D  OPnJ3bzTjf  g0sLjzBbdC  YhXF0wLsfa  mKg9vRmHNo  90T0MJu0DH   \n",
       "\n",
       "    item_id_6   item_id_7   item_id_8   item_id_9  ... item_id_991  \\\n",
       "0  eCL613RYIJ  r4SIjbucnQ  EfrACUgZoC  8W8bbWrtd2  ...         NaN   \n",
       "1  relvQBwWKb  NHdqdVNPAG  umAcyR4ruF  tuL0CRXFN7  ...         NaN   \n",
       "2  LvoCoE37bj  B1RAz6j2wo  rikHZfesKt  SEruLWaiyW  ...         NaN   \n",
       "3  iqis3H2tXL  gDsbAt7Hpr  akr2wUs0GU  4iIvzaIZaZ  ...         NaN   \n",
       "4  1mHzIaSLoz  P4qcBEBhJJ  ZX3Pbjwi0s  DFhmb9OynU  ...         NaN   \n",
       "\n",
       "   item_id_992  item_id_993  item_id_994  item_id_995  item_id_996  \\\n",
       "0          NaN          NaN          NaN          NaN          NaN   \n",
       "1          NaN          NaN          NaN          NaN          NaN   \n",
       "2          NaN          NaN          NaN          NaN          NaN   \n",
       "3          NaN          NaN          NaN          NaN          NaN   \n",
       "4          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "   item_id_997  item_id_998  item_id_999  item_id_1000  \n",
       "0          NaN          NaN          NaN           NaN  \n",
       "1          NaN          NaN          NaN           NaN  \n",
       "2          NaN          NaN          NaN           NaN  \n",
       "3          NaN          NaN          NaN           NaN  \n",
       "4          NaN          NaN          NaN           NaN  \n",
       "\n",
       "[5 rows x 1001 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "00ed3ff2-c869-4384-953f-06395359fa44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233847/1567586879.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  key = row[0]\n"
     ]
    }
   ],
   "source": [
    "def get_rec_list(df):\n",
    "    rec_list = {}  # Initialize an empty dictionary\n",
    "    for i, row in df.iterrows():\n",
    "        key = row[0]\n",
    "        values = row[1:11].tolist()  # Convert the remaining values to a list\n",
    "        rec_list[key] = values  # Add the key-value pair to the dictionary\n",
    "    return rec_list\n",
    "\n",
    "# Example usage\n",
    "rec_list = get_rec_list(df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ea6e9c09-9d73-4b9e-b386-ec843f8482c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17047"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NDCG(gt_dict, rec_list, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "803b388d-a0b9-499d-9898-bc9c90917fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0008570093387721419)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_ndcg_at_10(df4, gt_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2d0bbe06-b287-4d66-a2fa-1cc591f84f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1 = df1.copy()\n",
    "sub2 = df2.copy()\n",
    "sub3 = df3.copy()\n",
    "sub4 = df4.copy()\n",
    "sub5 = df5.copy()\n",
    "sub = pd.DataFrame()\n",
    "sub['user_id'] = sub1['user_id']\n",
    "sub1['prediction0'] = sub1.apply(lambda row: ' '.join(str(row[f'item_id_{i+1}']) for i in range(1000)), axis=1)\n",
    "sub2['prediction1'] = sub2.apply(lambda row: ' '.join(str(row[f'item_id_{i+1}']) for i in range(1000)), axis=1)\n",
    "sub3['prediction2'] = sub3.apply(lambda row: ' '.join(str(row[f'item_id_{i+1}']) for i in range(1000)), axis=1)\n",
    "# sub4['prediction3'] = sub4.apply(lambda row: ' '.join(str(row[f'item_id_{i+1}']) for i in range(1000)), axis=1)\n",
    "# sub5['prediction4'] = sub5.apply(lambda row: ' '.join(str(row[f'item_id_{i+1}']) for i in range(1000)), axis=1)\n",
    "sub['prediction0'] = sub1['prediction0']\n",
    "sub['prediction1'] = sub2['prediction1']\n",
    "sub['prediction2'] = sub3['prediction2']\n",
    "# sub['prediction3'] = sub4['prediction3']\n",
    "# sub['prediction4'] = sub5['prediction4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4b86b6f9-7f75-4894-9697-755ca9da0472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble dựa trên RRF\n",
    "def cust_blend(dt, W = [1.5,1,1]):\n",
    "    #Global ensemble weights\n",
    "    #W = [1.15,0.95,0.85]\n",
    "    \n",
    "    #Create a list of all model predictions\n",
    "    REC = []\n",
    "    REC.append(dt['prediction0'].split())\n",
    "    REC.append(dt['prediction1'].split())\n",
    "    REC.append(dt['prediction2'].split())\n",
    "    # REC.append(dt['prediction3'].split())\n",
    "    # REC.append(dt['prediction4'].split())\n",
    "\n",
    "    #Create a dictionary of items recommended. \n",
    "    #Assign a weight according the order of appearance and multiply by global weights\n",
    "    res = {}\n",
    "    for M in range(len(REC)):\n",
    "        for n, v in enumerate(REC[M]):\n",
    "            if v in res:\n",
    "                res[v] += (W[M]/(n+1))\n",
    "            else:\n",
    "                res[v] = (W[M]/(n+1))\n",
    "    \n",
    "    # Sort dictionary by item weights\n",
    "    res = list(dict(sorted(res.items(), key=lambda item: -item[1])).keys())\n",
    "    \n",
    "    # Return the top 12 itens only\n",
    "    return ' '.join(res[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "91debb0f-f10b-4af3-886e-4b7cdce92415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(sub, W):\n",
    "    tmp = sub.copy()\n",
    "    tmp['prediction'] = tmp.apply(lambda x: cust_blend(x, W), axis=1)\n",
    "    tmp = tmp[['user_id', 'prediction']]\n",
    "    value_lists = tmp['prediction'].str.split(\" \")\n",
    "    value_lists = value_lists.apply(lambda x: x + ['0'] * (1000 - len(x)) if len(x) < 1000 else x[:1000])\n",
    "    final = pd.DataFrame(value_lists.tolist(), index=tmp['user_id']).reset_index()\n",
    "    final.columns = ['user_id'] + ['item_id_' + str(i) for i in range(1, 1001)]\n",
    "    return calculate_ndcg_at_10(final, gt_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5c721a-5674-4af2-94a7-0984b8a1cc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_thresholds(true, pred, steps=50):\n",
    "\n",
    "    # SAVE TRIALS FOR PLOTTING\n",
    "    xs = [[],[],[],[],[]]\n",
    "    ys = [[],[],[],[],[]]\n",
    "\n",
    "    # COMPUTE BASELINE METRIC\n",
    "    threshold = [1.5, 2.5, 3.5, 4.5, 5.5]\n",
    "    pred2 = pd.cut(pred, [-np.inf] + threshold + [np.inf], \n",
    "                    labels=[1,2,3,4,5,6]).astype('int32')\n",
    "    best = cohen_kappa_score(true, pred2, weights=\"quadratic\")\n",
    "\n",
    "    # FIND FIVE OPTIMAL THRESHOLDS\n",
    "    for k in range(5):\n",
    "        for sign in [1,-1]:\n",
    "            v = threshold[k]\n",
    "            threshold2 = threshold.copy()\n",
    "            stop = 0\n",
    "            while stop<steps:\n",
    "\n",
    "                # TRY NEW THRESHOLD\n",
    "                v += sign * 0.001\n",
    "                threshold2[k] = v\n",
    "                pred2 = pd.cut(pred, [-np.inf] + threshold2 + [np.inf], \n",
    "                                labels=[1,2,3,4,5,6]).astype('int32')\n",
    "                metric = cohen_kappa_score(true, pred2, weights=\"quadratic\")\n",
    "\n",
    "                # SAVE TRIALS FOR PLOTTING\n",
    "                xs[k].append(v)\n",
    "                ys[k].append(metric)\n",
    "\n",
    "                # EARLY STOPPING\n",
    "                if metric<=best:\n",
    "                    stop += 1\n",
    "                else:\n",
    "                    stop = 0\n",
    "                    best = metric\n",
    "                    threshold = threshold2.copy()\n",
    "\n",
    "    # COMPUTE FINAL METRIC\n",
    "    pred2 = pd.cut(pred, [-np.inf] + threshold + [np.inf], \n",
    "                    labels=[1,2,3,4,5,6]).astype('int32')\n",
    "    best = cohen_kappa_score(true, pred2, weights=\"quadratic\")   \n",
    "\n",
    "    # RETURN RESULTS\n",
    "    threshold = [np.round(t,3) for t in threshold]\n",
    "    return best, threshold, xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0150de24-563c-466c-a22f-617786416186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid(*args):\n",
    "    if len(args) == 1:\n",
    "        for k in args[0]:\n",
    "            yield [k]\n",
    "    else:\n",
    "        for k in args[0]:\n",
    "            for rest in grid(*args[1:]):\n",
    "                yield([k] + rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8c8f5f20-efef-46bd-ba78-5ec6fd06743e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:   1%|▏         | 101/8000 [09:33<12:35:56,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Best W:  [0.1, 0.4, 0.5]\n",
      "Current Best ndcg:  0.13266021310281484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:   3%|▎         | 201/8000 [19:11<12:29:49,  5.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Best W:  [0.1, 0.4, 0.5]\n",
      "Current Best ndcg:  0.13266021310281484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:   4%|▍         | 301/8000 [28:48<12:13:52,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Best W:  [0.1, 1.3, 1.4]\n",
      "Current Best ndcg:  0.13275347559009176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:   5%|▍         | 397/8000 [38:07<12:10:14,  5.76s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[161], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     19\u001b[0m W \u001b[38;5;241m=\u001b[39m [XSimstd\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10\u001b[39m, XSimfull\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10\u001b[39m, XSimDenoise\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10\u001b[39m]\n\u001b[0;32m---> 20\u001b[0m ndcg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m res\u001b[38;5;241m.\u001b[39mappend([ndcg] \u001b[38;5;241m+\u001b[39m W)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ndcg\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39mbest:\n",
      "Cell \u001b[0;32mIn[142], line 3\u001b[0m, in \u001b[0;36meval\u001b[0;34m(sub, W)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval\u001b[39m(sub, W):\n\u001b[1;32m      2\u001b[0m     tmp \u001b[38;5;241m=\u001b[39m sub\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m----> 3\u001b[0m     tmp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcust_blend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     tmp \u001b[38;5;241m=\u001b[39m tmp[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m      5\u001b[0m     value_lists \u001b[38;5;241m=\u001b[39m tmp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10373\u001b[0m )\n\u001b[0;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[142], line 3\u001b[0m, in \u001b[0;36meval.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval\u001b[39m(sub, W):\n\u001b[1;32m      2\u001b[0m     tmp \u001b[38;5;241m=\u001b[39m sub\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m----> 3\u001b[0m     tmp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m tmp\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mcust_blend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m     tmp \u001b[38;5;241m=\u001b[39m tmp[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m      5\u001b[0m     value_lists \u001b[38;5;241m=\u001b[39m tmp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[132], line 20\u001b[0m, in \u001b[0;36mcust_blend\u001b[0;34m(dt, W)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(REC[M]):\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m res:\n\u001b[0;32m---> 20\u001b[0m         res[v] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (W[M]\u001b[38;5;241m/\u001b[39m(n\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m         res[v] \u001b[38;5;241m=\u001b[39m (W[M]\u001b[38;5;241m/\u001b[39m(n\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "f = open('data/grid_search/grid_search.txt', 'w')\n",
    "res = []\n",
    "best = 0\n",
    "best_W = []\n",
    "\n",
    "range_outer = range(1, 21, 1)\n",
    "range_middle = range(1, 21, 1)\n",
    "range_inner = range(1, 21, 1)\n",
    "total_iterations = len(range_outer) * len(range_middle) * len(range_inner)\n",
    "count = 0\n",
    "with tqdm(total=total_iterations, desc=\"Total Progress\") as pbar:\n",
    "    for XSimstd in range_outer:\n",
    "        for XSimfull in range_middle:\n",
    "            for XSimDenoise in range_inner:\n",
    "                pbar.update(1)\n",
    "                count += 1\n",
    "                stop = 0\n",
    "                W = [XSimstd/10, XSimfull/10, XSimDenoise/10]\n",
    "                ndcg = eval(sub, W)\n",
    "                res.append([ndcg] + W)\n",
    "                if ndcg<=best:\n",
    "                    stop += 1\n",
    "                else:\n",
    "                    stop = 0\n",
    "                    best = ndcg\n",
    "                    best_W = W\n",
    "                    f.write(f'{W}\\n')\n",
    "                if count%100 == 0:\n",
    "                    print('Current Best W: ', best_W)\n",
    "                    print('Current Best ndcg: ', best)\n",
    "                # if stop >= 10: break\n",
    "sorted_list = sorted(res, key=lambda x: x[0], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6589a818-131e-4663-ac3e-04ad4506f8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/grid_search/grid_search.txt', 'w') as f:\n",
    "    for line in sorted_list[0]:\n",
    "        f.write(f\"{line}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f56d24-1df2-4415-8e1f-347d01f977d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
