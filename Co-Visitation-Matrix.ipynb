{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":38760,"databundleVersionId":4493939,"sourceType":"competition"},{"sourceId":4436180,"sourceType":"datasetVersion","datasetId":2597726},{"sourceId":9933751,"sourceType":"datasetVersion","datasetId":6047721},{"sourceId":9954612,"sourceType":"datasetVersion","datasetId":5965973}],"dockerImageVersionId":30301,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Candidate ReRank Model using Handcrafted Rules\nIn this notebook, we present a \"candidate rerank\" model using handcrafted rules. We can improve this model by engineering features, merging them unto items and users, and training a reranker model (such as XGB) to choose our final 20. Furthermore to tune and improve this notebook, we should build a local CV scheme to experiment new logic and/or models.\n\nUPDATE: I published a notebook to compute validation score [here][10] using Radek's scheme described [here][11].\n\nNote in this competition, a \"session\" actually means a unique \"user\". So our task is to predict what each of the `1,671,803` test \"users\" (i.e. \"sessions\") will do in the future. For each test \"user\" (i.e. \"session\") we must predict what they will `click`, `cart`, and `order` during the remainder of the week long test period.\n\n### Step 1 - Generate Candidates\nFor each test user, we generate possible choices, i.e. candidates. In this notebook, we generate candidates from 5 sources:\n* User history of clicks, carts, orders\n* Most popular 20 clicks, carts, orders during test week\n* Co-visitation matrix of click/cart/order to cart/order with type weighting\n* Co-visitation matrix of cart/order to cart/order called buy2buy\n* Co-visitation matrix of click/cart/order to clicks with time weighting\n\n### Step 2 - ReRank and Choose 20\nGiven the list of candidates, we must select 20 to be our predictions. In this notebook, we do this with a set of handcrafted rules. We can improve our predictions by training an XGBoost model to select for us. Our handcrafted rules give priority to:\n* Most recent previously visited items\n* Items previously visited multiple times\n* Items previously in cart or order\n* Co-visitation matrix of cart/order to cart/order\n* Current popular items\n\n![](https://raw.githubusercontent.com/cdeotte/Kaggle_Images/main/Nov-2022/c_r_model.png)\n  \n# Credits\nWe thank many Kagglers who have shared ideas. We use co-visitation matrix idea from Vladimir [here][1]. We use groupby sort logic from Sinan in comment section [here][4]. We use duplicate prediction removal logic from Radek [here][5]. We use multiple visit logic from Pietro [here][2]. We use type weighting logic from Ingvaras [here][3]. We use leaky test data from my previous notebook [here][4]. And some ideas may have originated from Tawara [here][6] and KJ [here][7]. We use Colum2131's parquets [here][8]. Above image is from Ravi's discussion about candidate rerank models [here][9]\n\n[1]: https://www.kaggle.com/code/vslaykovsky/co-visitation-matrix\n[2]: https://www.kaggle.com/code/pietromaldini1/multiple-clicks-vs-latest-items\n[3]: https://www.kaggle.com/code/ingvarasgalinskas/item-type-vs-multiple-clicks-vs-latest-items\n[4]: https://www.kaggle.com/code/cdeotte/test-data-leak-lb-boost\n[5]: https://www.kaggle.com/code/radek1/co-visitation-matrix-simplified-imprvd-logic\n[6]: https://www.kaggle.com/code/ttahara/otto-mors-aid-frequency-baseline\n[7]: https://www.kaggle.com/code/whitelily/co-occurrence-baseline\n[8]: https://www.kaggle.com/datasets/columbia2131/otto-chunk-data-inparquet-format\n[9]: https://www.kaggle.com/competitions/otto-recommender-system/discussion/364721\n[10]: https://www.kaggle.com/cdeotte/compute-validation-score-cv-564\n[11]: https://www.kaggle.com/competitions/otto-recommender-system/discussion/364991","metadata":{"papermill":{"duration":0.005198,"end_time":"2022-11-10T16:03:20.966987","exception":false,"start_time":"2022-11-10T16:03:20.961789","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Notes\nBelow are notes about versions:\n* **Version 1 LB 0.573** Uses popular ideas from public notebooks and adds additional co-visitation matrices and additional logic. Has CV `0.563`. See validation notebook version 2 [here][1].\n* **Version 2 LB 573** Refactor logic for `suggest_buys(df)` to make it clear how new co-visitation matrices are reranking the candidates by adding to candidate weights. Also new logic boosts CV by `+0.0003`. Also LB is slightly better too. See validation notebook version 3 [here][1]\n* **Version 3** is the same as version 2 but 1.5x faster co-visitation matrix computation!\n* **Version 4 LB 575** Use top20 for clicks and top15 for carts and buys (instead of top40 and top40). This boosts CV `+0.0015` hooray! New CV is `0.5647`. See validation version 5 [here][1]\n* **Version 5** is the same as version 4 but 2x faster co-visitation matrix computation! (and 3x faster than version 1)\n* **Version 6** Stay tuned for more versions...\n\n[1]: https://www.kaggle.com/code/cdeotte/compute-validation-score-cv-564","metadata":{}},{"cell_type":"markdown","source":"# Step 1 - Candidate Generation with RAPIDS\nFor candidate generation, we build three co-visitation matrices. One computes the popularity of cart/order given a user's previous click/cart/order. We apply type weighting to this matrix. One computes the popularity of cart/order given a user's previous cart/order. We call this \"buy2buy\" matrix. One computes the popularity of clicks given a user previously click/cart/order.  We apply time weighting to this matrix. We will use RAPIDS cuDF GPU to compute these matrices quickly!","metadata":{"papermill":{"duration":0.00373,"end_time":"2022-11-10T16:03:20.9748","exception":false,"start_time":"2022-11-10T16:03:20.97107","status":"completed"},"tags":[]}},{"cell_type":"code","source":"VER = 5\n\nimport pandas as pd, numpy as np\nfrom tqdm.notebook import tqdm\nimport os, sys, pickle, glob, gc\nfrom collections import Counter\n# import cudf, itertools\n# print('We will use RAPIDS version',cudf.__version__)","metadata":{"papermill":{"duration":3.036143,"end_time":"2022-11-10T16:03:24.014816","exception":false,"start_time":"2022-11-10T16:03:20.978673","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-20T07:21:06.626096Z","iopub.execute_input":"2024-11-20T07:21:06.626796Z","iopub.status.idle":"2024-11-20T07:21:06.779935Z","shell.execute_reply.started":"2024-11-20T07:21:06.626619Z","shell.execute_reply":"2024-11-20T07:21:06.778873Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## Compute Three Co-visitation Matrices with RAPIDS\nWe will compute 3 co-visitation matrices using RAPIDS cuDF on GPU. This is 30x faster than using Pandas CPU like other public notebooks! For maximum speed, set the variable `DISK_PIECES` to the smallest number possible based on the GPU you are using without incurring memory errors. If you run this code offline with 32GB GPU ram, then you can use `DISK_PIECES = 1` and compute each co-visitation matrix in almost 1 minute! Kaggle's GPU only has 16GB ram, so we use `DISK_PIECES = 4` and it takes an amazing 3 minutes each! Below are some of the tricks to speed up computation\n* Use RAPIDS cuDF GPU instead of Pandas CPU\n* Read disk once and save in CPU RAM for later GPU multiple use\n* Process largest amount of data possible on GPU at one time\n* Merge data in two stages. Multiple small to single medium. Multiple medium to single large.\n* Write result as parquet instead of dictionary","metadata":{"papermill":{"duration":0.00424,"end_time":"2022-11-10T16:03:24.023816","exception":false,"start_time":"2022-11-10T16:03:24.019576","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/vhac-recsys/training_set.csv')\n\nuser_list = df.groupby('UserId')['ItemId'].nunique()\nuser_list_denoise = user_list[(user_list<=20) & (user_list>=3)].index.to_list()\ndf = df[df.UserId.isin(user_list_denoise)]\n\ndf['type'] = df['Purchase']\ndf.shape","metadata":{"papermill":{"duration":0.063943,"end_time":"2022-11-10T16:03:24.091816","exception":false,"start_time":"2022-11-10T16:03:24.027873","status":"completed"},"tags":[],"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-11-20T07:24:17.759881Z","iopub.execute_input":"2024-11-20T07:24:17.760841Z","iopub.status.idle":"2024-11-20T07:24:18.314483Z","shell.execute_reply.started":"2024-11-20T07:24:17.760793Z","shell.execute_reply":"2024-11-20T07:24:18.313233Z"},"trusted":true},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(257122, 5)"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"## 1) \"Carts Orders\" Co-visitation Matrix - Type Weighted","metadata":{"papermill":{"duration":0.004089,"end_time":"2022-11-10T16:03:24.100502","exception":false,"start_time":"2022-11-10T16:03:24.096413","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# CREATE PAIRS\ndf = df.merge(df,on='UserId')\ndf = df.loc[(df.ItemId_x != df.ItemId_y) ]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T07:24:19.936029Z","iopub.execute_input":"2024-11-20T07:24:19.936455Z","iopub.status.idle":"2024-11-20T07:24:21.060203Z","shell.execute_reply.started":"2024-11-20T07:24:19.936421Z","shell.execute_reply":"2024-11-20T07:24:21.058837Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"type_weight = {0:1, 1:5}\n\n# ASSIGN WEIGHTS\ndf = df[['UserId', 'ItemId_x', 'ItemId_y','type_y']].drop_duplicates(['UserId', 'ItemId_x', 'ItemId_y'])\ndf['wgt'] = df.type_y.map(type_weight)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T07:24:21.841301Z","iopub.execute_input":"2024-11-20T07:24:21.84179Z","iopub.status.idle":"2024-11-20T07:24:22.992191Z","shell.execute_reply.started":"2024-11-20T07:24:21.841748Z","shell.execute_reply":"2024-11-20T07:24:22.99097Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"df = df[['ItemId_x', 'ItemId_y','wgt']]\ndf.wgt = df.wgt.astype('float32')\ndf = df.groupby(['ItemId_x', 'ItemId_y']).wgt.sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T07:24:22.994147Z","iopub.execute_input":"2024-11-20T07:24:22.994527Z","iopub.status.idle":"2024-11-20T07:24:24.505485Z","shell.execute_reply.started":"2024-11-20T07:24:22.994489Z","shell.execute_reply":"2024-11-20T07:24:24.50426Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# CONVERT MATRIX TO DICTIONARY\ndf = df.reset_index()\ndf = df.sort_values(['ItemId_x','wgt'],ascending=[True,False])\n# SAVE TOP 40\ndf = df.reset_index(drop=True)\ndf['n'] = df.groupby('ItemId_x').ItemId_y.cumcount()\ndf = df.loc[df.n<15].drop('n',axis=1)","metadata":{"papermill":{"duration":566.561189,"end_time":"2022-11-10T16:12:50.666123","exception":false,"start_time":"2022-11-10T16:03:24.104934","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-20T07:24:24.507679Z","iopub.execute_input":"2024-11-20T07:24:24.508149Z","iopub.status.idle":"2024-11-20T07:24:25.565542Z","shell.execute_reply.started":"2024-11-20T07:24:24.508105Z","shell.execute_reply":"2024-11-20T07:24:25.564553Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"cart_order = df.copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T07:24:25.567137Z","iopub.execute_input":"2024-11-20T07:24:25.567458Z","iopub.status.idle":"2024-11-20T07:24:25.584916Z","shell.execute_reply.started":"2024-11-20T07:24:25.567428Z","shell.execute_reply":"2024-11-20T07:24:25.583865Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"cart_order.to_csv('cart_order_denoise.csv', index = False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T07:24:41.256977Z","iopub.execute_input":"2024-11-20T07:24:41.257438Z","iopub.status.idle":"2024-11-20T07:24:42.805376Z","shell.execute_reply.started":"2024-11-20T07:24:41.257404Z","shell.execute_reply":"2024-11-20T07:24:42.804435Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## 2) \"Buy2Buy\" Co-visitation Matrix","metadata":{"papermill":{"duration":0.03219,"end_time":"2022-11-10T16:12:50.730634","exception":false,"start_time":"2022-11-10T16:12:50.698444","status":"completed"},"tags":[]}},{"cell_type":"code","source":"%%time\ndf = pd.read_csv('/kaggle/input/vhac-recsys/training_set.csv')\n\nuser_list = df.groupby('UserId')['ItemId'].nunique()\nuser_list_denoise = user_list[(user_list<=20) & (user_list>=3)].index.to_list()\ndf = df[df.UserId.isin(user_list_denoise)]\n\ndf['type'] = df['Purchase']\ndf.shape\n\ndf = df.loc[df['type'].isin([1])] # ONLY WANT CARTS AND ORDERS\n# CREATE PAIRS\ndf = df.merge(df,on='UserId')\ndf = df.loc[(df.ItemId_x != df.ItemId_y)] # 14 DAYS\n# ASSIGN WEIGHTS\ndf = df[['UserId', 'ItemId_x', 'ItemId_y','type_y']].drop_duplicates(['UserId', 'ItemId_x', 'ItemId_y'])\ndf['wgt'] = 1\ndf = df[['ItemId_x', 'ItemId_y','wgt']]\ndf.wgt = df.wgt.astype('float32')\ndf = df.groupby(['ItemId_x', 'ItemId_y']).wgt.sum()\n\n# CONVERT MATRIX TO DICTIONARY\ndf = df.reset_index()\ndf = df.sort_values(['ItemId_x','wgt'],ascending=[True,False])\n# SAVE TOP 40\ndf = df.reset_index(drop=True)\ndf['n'] = df.groupby('ItemId_x').ItemId_y.cumcount()\ndf = df.loc[df.n<15].drop('n',axis=1)\n# SAVE PART TO DISK (convert to pandas first uses less memory)\n\nbuy_order = df.copy()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"papermill":{"duration":113.735315,"end_time":"2022-11-10T16:14:44.498182","exception":false,"start_time":"2022-11-10T16:12:50.762867","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-20T07:24:52.301126Z","iopub.execute_input":"2024-11-20T07:24:52.301535Z","iopub.status.idle":"2024-11-20T07:24:52.885374Z","shell.execute_reply.started":"2024-11-20T07:24:52.301504Z","shell.execute_reply":"2024-11-20T07:24:52.884303Z"},"trusted":true},"outputs":[{"name":"stdout","text":"CPU times: user 569 ms, sys: 7.67 ms, total: 576 ms\nWall time: 576 ms\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"buy_order.to_csv('buy_order_denoise.csv', index = False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T07:24:59.456779Z","iopub.execute_input":"2024-11-20T07:24:59.457271Z","iopub.status.idle":"2024-11-20T07:24:59.517216Z","shell.execute_reply.started":"2024-11-20T07:24:59.457233Z","shell.execute_reply":"2024-11-20T07:24:59.515876Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"# Click order","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/vhac-recsys/training_set.csv')\nuser_list = df.groupby('UserId')['ItemId'].nunique()\nuser_list_denoise = user_list[(user_list<=20) & (user_list>=3)].index.to_list()\ndf = df[df.UserId.isin(user_list_denoise)]\n\ndef add_action_num_reverse_chrono(df):\n    df['action_num_reverse_chrono'] = df.groupby('UserId').cumcount(ascending=False)\n    return df\n\ndef add_session_length(df):\n    tmp = df.groupby('UserId')['ItemId'].nunique().reset_index().rename(columns={'ItemId': 'session_length'})\n    df = df.merge(tmp, on = 'UserId', how = 'left')\n    return df\n\ndef add_log_recency_score(df):\n    linear_interpolation = 0.1 + ((1-0.1) / (df['session_length']-1)) * (df['session_length']-df['action_num_reverse_chrono']-1)\n    df['log_recency_score'] = pd.Series(2**linear_interpolation - 1).fillna(1)\n    return df\n\ndef add_type_weighted_log_recency_score(df):\n    type_weights = {0:1, 1:5}\n    type_weighted_log_recency_score = pd.Series(df['Purchase'].apply(lambda x: type_weights[x]) * df['log_recency_score'])\n    df['type_weighted_log_recency_score'] = type_weighted_log_recency_score\n    return df\n\ndef apply(df, pipeline):\n    for f in pipeline:\n        df = f(df)\n    return df\n\npipeline = [add_action_num_reverse_chrono, add_session_length, add_log_recency_score, add_type_weighted_log_recency_score]\n\ndf = apply(df, pipeline)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T08:39:11.981497Z","iopub.execute_input":"2024-11-20T08:39:11.981905Z","iopub.status.idle":"2024-11-20T08:39:12.9755Z","shell.execute_reply.started":"2024-11-20T08:39:11.98187Z","shell.execute_reply":"2024-11-20T08:39:12.974474Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"%%time\ndf['ts'] = df['action_num_reverse_chrono']\n# CREATE PAIRS\ndf = df.merge(df,on='UserId')\ndf = df.loc[(df.ItemId_x != df.ItemId_y)]\n# ASSIGN WEIGHTS\ndf = df[['UserId', 'ItemId_x', 'ItemId_y','ts_x']].drop_duplicates(['UserId', 'ItemId_x', 'ItemId_y'])\ndf['wgt'] = 1 + 3*(df.ts_x - 1)/100\ndf = df[['ItemId_x', 'ItemId_y','wgt']]\ndf.wgt = df.wgt.astype('float32')\ndf = df.groupby(['ItemId_x', 'ItemId_y']).wgt.sum()\n\n# CONVERT MATRIX TO DICTIONARY\ndf = df.reset_index()\ndf = df.sort_values(['ItemId_x','wgt'],ascending=[True,False])\n# SAVE TOP 40\ndf = df.reset_index(drop=True)\ndf['n'] = df.groupby('ItemId_x').ItemId_y.cumcount()\ndf = df.loc[df.n<15].drop('n',axis=1)\n# SAVE PART TO DISK (convert to pandas first uses less memory)\n\nclick_order = df.copy()\nclick_order","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T08:38:42.761734Z","iopub.execute_input":"2024-11-20T08:38:42.762136Z","iopub.status.idle":"2024-11-20T08:38:48.56319Z","shell.execute_reply.started":"2024-11-20T08:38:42.762104Z","shell.execute_reply":"2024-11-20T08:38:48.5619Z"}},"outputs":[{"name":"stdout","text":"CPU times: user 4.63 s, sys: 1.18 s, total: 5.81 s\nWall time: 5.79 s\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"           ItemId_x    ItemId_y   wgt\n0        004POG3wLH  rbXvgoHURF  6.32\n1        004POG3wLH  Djzr4rtQ1d  6.14\n2        004POG3wLH  a6fTWfqc6h  5.02\n3        004POG3wLH  z2JS9EHqBR  4.02\n4        004POG3wLH  52SfqaqILe  3.90\n...             ...         ...   ...\n1674250  zzyfHckCgU  17QWtUfOqj  6.02\n1674251  zzyfHckCgU  PzcBCDf6R4  5.93\n1674252  zzyfHckCgU  VkffBXXhVi  5.42\n1674253  zzyfHckCgU  B3IeyxvddX  4.99\n1674254  zzyfHckCgU  MVYheAcD0F  4.72\n\n[746383 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ItemId_x</th>\n      <th>ItemId_y</th>\n      <th>wgt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>004POG3wLH</td>\n      <td>rbXvgoHURF</td>\n      <td>6.32</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>004POG3wLH</td>\n      <td>Djzr4rtQ1d</td>\n      <td>6.14</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>004POG3wLH</td>\n      <td>a6fTWfqc6h</td>\n      <td>5.02</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>004POG3wLH</td>\n      <td>z2JS9EHqBR</td>\n      <td>4.02</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>004POG3wLH</td>\n      <td>52SfqaqILe</td>\n      <td>3.90</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1674250</th>\n      <td>zzyfHckCgU</td>\n      <td>17QWtUfOqj</td>\n      <td>6.02</td>\n    </tr>\n    <tr>\n      <th>1674251</th>\n      <td>zzyfHckCgU</td>\n      <td>PzcBCDf6R4</td>\n      <td>5.93</td>\n    </tr>\n    <tr>\n      <th>1674252</th>\n      <td>zzyfHckCgU</td>\n      <td>VkffBXXhVi</td>\n      <td>5.42</td>\n    </tr>\n    <tr>\n      <th>1674253</th>\n      <td>zzyfHckCgU</td>\n      <td>B3IeyxvddX</td>\n      <td>4.99</td>\n    </tr>\n    <tr>\n      <th>1674254</th>\n      <td>zzyfHckCgU</td>\n      <td>MVYheAcD0F</td>\n      <td>4.72</td>\n    </tr>\n  </tbody>\n</table>\n<p>746383 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"click_order.to_csv('click_order_action_num_reverse_denoise.csv', index = False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T08:38:48.565158Z","iopub.execute_input":"2024-11-20T08:38:48.565524Z","iopub.status.idle":"2024-11-20T08:38:50.241683Z","shell.execute_reply.started":"2024-11-20T08:38:48.565494Z","shell.execute_reply":"2024-11-20T08:38:50.240543Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"%%time\ndf['ts'] = df['log_recency_score']\n# CREATE PAIRS\ndf = df.merge(df,on='UserId')\ndf = df.loc[(df.ItemId_x != df.ItemId_y)]\n# ASSIGN WEIGHTS\ndf = df[['UserId', 'ItemId_x', 'ItemId_y','ts_x']].drop_duplicates(['UserId', 'ItemId_x', 'ItemId_y'])\ndf['wgt'] = df.ts_x \ndf = df[['ItemId_x', 'ItemId_y','wgt']]\ndf.wgt = df.wgt.astype('float32')\ndf = df.groupby(['ItemId_x', 'ItemId_y']).wgt.sum()\n\n# CONVERT MATRIX TO DICTIONARY\ndf = df.reset_index()\ndf = df.sort_values(['ItemId_x','wgt'],ascending=[True,False])\n# SAVE TOP 40\ndf = df.reset_index(drop=True)\ndf['n'] = df.groupby('ItemId_x').ItemId_y.cumcount()\ndf = df.loc[df.n<15].drop('n',axis=1)\n# SAVE PART TO DISK (convert to pandas first uses less memory)\n\nclick_order = df.copy()\nclick_order","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T08:39:00.763868Z","iopub.execute_input":"2024-11-20T08:39:00.764252Z","iopub.status.idle":"2024-11-20T08:39:05.981052Z","shell.execute_reply.started":"2024-11-20T08:39:00.76422Z","shell.execute_reply":"2024-11-20T08:39:05.979888Z"}},"outputs":[{"name":"stdout","text":"CPU times: user 4.47 s, sys: 732 ms, total: 5.2 s\nWall time: 5.2 s\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"           ItemId_x    ItemId_y       wgt\n0        004POG3wLH  Djzr4rtQ1d  1.852012\n1        004POG3wLH  a6fTWfqc6h  1.546204\n2        004POG3wLH  0jUQo5avOJ  1.271901\n3        004POG3wLH  P04Gvoewcw  1.104455\n4        004POG3wLH  rbXvgoHURF  1.035571\n...             ...         ...       ...\n1674250  zzyfHckCgU  PzcBCDf6R4  2.328075\n1674251  zzyfHckCgU  BxOTdTTVgN  2.228202\n1674252  zzyfHckCgU  XROzLQhTXa  2.021708\n1674253  zzyfHckCgU  ELwOkhgtMG  1.852114\n1674254  zzyfHckCgU  q7gITyZegm  1.776817\n\n[746383 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ItemId_x</th>\n      <th>ItemId_y</th>\n      <th>wgt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>004POG3wLH</td>\n      <td>Djzr4rtQ1d</td>\n      <td>1.852012</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>004POG3wLH</td>\n      <td>a6fTWfqc6h</td>\n      <td>1.546204</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>004POG3wLH</td>\n      <td>0jUQo5avOJ</td>\n      <td>1.271901</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>004POG3wLH</td>\n      <td>P04Gvoewcw</td>\n      <td>1.104455</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>004POG3wLH</td>\n      <td>rbXvgoHURF</td>\n      <td>1.035571</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1674250</th>\n      <td>zzyfHckCgU</td>\n      <td>PzcBCDf6R4</td>\n      <td>2.328075</td>\n    </tr>\n    <tr>\n      <th>1674251</th>\n      <td>zzyfHckCgU</td>\n      <td>BxOTdTTVgN</td>\n      <td>2.228202</td>\n    </tr>\n    <tr>\n      <th>1674252</th>\n      <td>zzyfHckCgU</td>\n      <td>XROzLQhTXa</td>\n      <td>2.021708</td>\n    </tr>\n    <tr>\n      <th>1674253</th>\n      <td>zzyfHckCgU</td>\n      <td>ELwOkhgtMG</td>\n      <td>1.852114</td>\n    </tr>\n    <tr>\n      <th>1674254</th>\n      <td>zzyfHckCgU</td>\n      <td>q7gITyZegm</td>\n      <td>1.776817</td>\n    </tr>\n  </tbody>\n</table>\n<p>746383 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"click_order.to_csv('click_order_log_recency_score_denoise.csv', index = False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T08:39:06.777406Z","iopub.execute_input":"2024-11-20T08:39:06.777838Z","iopub.status.idle":"2024-11-20T08:39:08.588126Z","shell.execute_reply.started":"2024-11-20T08:39:06.777803Z","shell.execute_reply":"2024-11-20T08:39:08.586951Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"%%time\ndf['ts'] = df['type_weighted_log_recency_score']\n# CREATE PAIRS\ndf = df.merge(df,on='UserId')\ndf = df.loc[(df.ItemId_x != df.ItemId_y)]\n# ASSIGN WEIGHTS\ndf = df[['UserId', 'ItemId_x', 'ItemId_y','ts_x']].drop_duplicates(['UserId', 'ItemId_x', 'ItemId_y'])\ndf['wgt'] = df.ts_x \ndf = df[['ItemId_x', 'ItemId_y','wgt']]\ndf.wgt = df.wgt.astype('float32')\ndf = df.groupby(['ItemId_x', 'ItemId_y']).wgt.sum()\n\n# CONVERT MATRIX TO DICTIONARY\ndf = df.reset_index()\ndf = df.sort_values(['ItemId_x','wgt'],ascending=[True,False])\n# SAVE TOP 40\ndf = df.reset_index(drop=True)\ndf['n'] = df.groupby('ItemId_x').ItemId_y.cumcount()\ndf = df.loc[df.n<15].drop('n',axis=1)\n# SAVE PART TO DISK (convert to pandas first uses less memory)\n\nclick_order = df.copy()\nclick_order","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T08:39:16.888223Z","iopub.execute_input":"2024-11-20T08:39:16.888625Z","iopub.status.idle":"2024-11-20T08:39:22.173565Z","shell.execute_reply.started":"2024-11-20T08:39:16.888593Z","shell.execute_reply":"2024-11-20T08:39:22.172211Z"}},"outputs":[{"name":"stdout","text":"CPU times: user 4.49 s, sys: 777 ms, total: 5.27 s\nWall time: 5.27 s\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"           ItemId_x    ItemId_y       wgt\n0        004POG3wLH  Djzr4rtQ1d  1.852012\n1        004POG3wLH  rbXvgoHURF  1.670348\n2        004POG3wLH  a6fTWfqc6h  1.546204\n3        004POG3wLH  2WiKPnbBA7  1.534573\n4        004POG3wLH  QOOxusL4GZ  1.324271\n...             ...         ...       ...\n1674250  zzyfHckCgU  PzcBCDf6R4  2.328075\n1674251  zzyfHckCgU  BxOTdTTVgN  2.228202\n1674252  zzyfHckCgU  XROzLQhTXa  2.021708\n1674253  zzyfHckCgU  ELwOkhgtMG  1.852114\n1674254  zzyfHckCgU  q7gITyZegm  1.776817\n\n[746383 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ItemId_x</th>\n      <th>ItemId_y</th>\n      <th>wgt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>004POG3wLH</td>\n      <td>Djzr4rtQ1d</td>\n      <td>1.852012</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>004POG3wLH</td>\n      <td>rbXvgoHURF</td>\n      <td>1.670348</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>004POG3wLH</td>\n      <td>a6fTWfqc6h</td>\n      <td>1.546204</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>004POG3wLH</td>\n      <td>2WiKPnbBA7</td>\n      <td>1.534573</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>004POG3wLH</td>\n      <td>QOOxusL4GZ</td>\n      <td>1.324271</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1674250</th>\n      <td>zzyfHckCgU</td>\n      <td>PzcBCDf6R4</td>\n      <td>2.328075</td>\n    </tr>\n    <tr>\n      <th>1674251</th>\n      <td>zzyfHckCgU</td>\n      <td>BxOTdTTVgN</td>\n      <td>2.228202</td>\n    </tr>\n    <tr>\n      <th>1674252</th>\n      <td>zzyfHckCgU</td>\n      <td>XROzLQhTXa</td>\n      <td>2.021708</td>\n    </tr>\n    <tr>\n      <th>1674253</th>\n      <td>zzyfHckCgU</td>\n      <td>ELwOkhgtMG</td>\n      <td>1.852114</td>\n    </tr>\n    <tr>\n      <th>1674254</th>\n      <td>zzyfHckCgU</td>\n      <td>q7gITyZegm</td>\n      <td>1.776817</td>\n    </tr>\n  </tbody>\n</table>\n<p>746383 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"click_order.to_csv('click_order_type_weighted_log_recency_score_denoise.csv', index = False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T08:39:22.639652Z","iopub.execute_input":"2024-11-20T08:39:22.640095Z","iopub.status.idle":"2024-11-20T08:39:24.512616Z","shell.execute_reply.started":"2024-11-20T08:39:22.640062Z","shell.execute_reply":"2024-11-20T08:39:24.511488Z"}},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":"# Step 2 - ReRank (choose 20) using handcrafted rules\nFor description of the handcrafted rules, read this notebook's intro.","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/vhac-recsys-standard/public_testset.csv', names = ['user_id']+[f'item_id_{i}' for i in range(1,1001)])","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"execution":{"iopub.status.busy":"2024-11-11T15:52:01.899081Z","iopub.execute_input":"2024-11-11T15:52:01.899469Z","iopub.status.idle":"2024-11-11T15:52:03.591987Z","shell.execute_reply.started":"2024-11-11T15:52:01.899433Z","shell.execute_reply":"2024-11-11T15:52:03.590531Z"},"trusted":true},"outputs":[],"execution_count":39},{"cell_type":"code","source":"%%time\ndef pqt_to_dict(df):\n    return df.groupby('ItemId_x').ItemId_y.apply(list).to_dict()\n# LOAD THREE CO-VISITATION MATRICES\n\ntop_20_buys = pqt_to_dict(cart_order)\n\ntop_20_buy2buy = pqt_to_dict( buy_order )","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"execution":{"iopub.status.busy":"2024-11-11T15:52:03.593557Z","iopub.execute_input":"2024-11-11T15:52:03.594078Z","iopub.status.idle":"2024-11-11T15:52:06.336299Z","shell.execute_reply.started":"2024-11-11T15:52:03.594032Z","shell.execute_reply":"2024-11-11T15:52:06.335095Z"},"trusted":true},"outputs":[{"name":"stdout","text":"CPU times: user 2.72 s, sys: 17.8 ms, total: 2.74 s\nWall time: 2.74 s\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"print( len( top_20_buy2buy ), len( top_20_buys ) )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T15:52:06.33973Z","iopub.execute_input":"2024-11-11T15:52:06.340125Z","iopub.status.idle":"2024-11-11T15:52:06.346866Z","shell.execute_reply.started":"2024-11-11T15:52:06.340089Z","shell.execute_reply":"2024-11-11T15:52:06.345419Z"}},"outputs":[{"name":"stdout","text":"6438 72643\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"#type_weight_multipliers = {'clicks': 1, 'carts': 6, 'orders': 3}\ntype_weight_multipliers = {0: 1, 1: 5}\n\ndf = pd.read_csv('/kaggle/input/vhac-recsys-standard/data_final.csv')\ndf['type'] = df['Purchase']\n\ndef suggest_buys(df):\n    # USER HISTORY AIDS AND TYPES\n    aids= df.ItemId.tolist()\n    types = df.type.tolist()\n    # UNIQUE AIDS AND UNIQUE BUYS\n    unique_aids = list(dict.fromkeys(aids[::-1] ))\n    df = df.loc[(df['type']==1)]\n    unique_buys = list(dict.fromkeys( df.ItemId.tolist()[::-1] ))\n    # USE \"CART ORDER\" CO-VISITATION MATRIX\n    aids2 = list(itertools.chain(*[top_20_buys[aid] for aid in unique_aids if aid in top_20_buys]))\n    # USE \"BUY2BUY\" CO-VISITATION MATRIX\n    aids3 = list(itertools.chain(*[top_20_buy2buy[aid] for aid in unique_buys if aid in top_20_buy2buy]))\n    # RERANK CANDIDATES\n    result = [aid2 for aid2, cnt in Counter(aids2+aids3).most_common(20) if aid2 not in unique_aids] \n    # USE TOP20 TEST ORDERS\n    return result ","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"execution":{"iopub.status.busy":"2024-11-11T15:52:06.348504Z","iopub.execute_input":"2024-11-11T15:52:06.348911Z","iopub.status.idle":"2024-11-11T15:52:06.587648Z","shell.execute_reply.started":"2024-11-11T15:52:06.348859Z","shell.execute_reply":"2024-11-11T15:52:06.586581Z"},"trusted":true},"outputs":[],"execution_count":42},{"cell_type":"markdown","source":"# Create Submission CSV\nInferring test data with Pandas groupby is slow. We need to accelerate the following code.","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}},{"cell_type":"code","source":"%%time\nimport itertools\npred_df_buys = df.groupby([\"UserId\"]).apply(\n    lambda x: suggest_buys(x)\n)","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"execution":{"iopub.status.busy":"2024-11-11T15:52:06.589107Z","iopub.execute_input":"2024-11-11T15:52:06.589505Z","iopub.status.idle":"2024-11-11T15:52:34.354854Z","shell.execute_reply.started":"2024-11-11T15:52:06.589469Z","shell.execute_reply":"2024-11-11T15:52:34.35362Z"},"trusted":true},"outputs":[{"name":"stdout","text":"CPU times: user 27.7 s, sys: 76.3 ms, total: 27.8 s\nWall time: 27.8 s\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"pred_df_buys = pred_df_buys.reset_index()\npred_df_buys.rename(columns = {0: \"list_item\"}, inplace = True)\nsubmit = pred_df_buys[pred_df_buys.UserId.isin(test.user_id)]","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"execution":{"iopub.status.busy":"2024-11-11T15:52:34.359792Z","iopub.execute_input":"2024-11-11T15:52:34.36034Z","iopub.status.idle":"2024-11-11T15:52:34.396346Z","shell.execute_reply.started":"2024-11-11T15:52:34.360295Z","shell.execute_reply":"2024-11-11T15:52:34.394901Z"},"trusted":true},"outputs":[],"execution_count":44},{"cell_type":"code","source":"# Hàm để tạo ra một danh sách có độ dài 1000, điền thêm NaN nếu cần\ndef pad_list(lst, length=1000):\n    return lst + [\"0\"] * (length - len(lst))\n\n# Tạo DataFrame với 1000 cột\nsubmit = pd.DataFrame(\n    submit['list_item'].apply(lambda x: pad_list(x)).tolist(),\n    index=submit['UserId'],\n    columns=[f'item_{i+1}' for i in range(1000)]\n).reset_index()\n\n# Đổi tên cột index thành user_id\nsubmit.rename(columns={'index': 'UserId'}, inplace=True)\n\n# Hiển thị DataFrame\nsubmit.to_csv('predict.csv', index = None, header = None)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T15:52:34.398463Z","iopub.execute_input":"2024-11-11T15:52:34.398967Z","iopub.status.idle":"2024-11-11T15:52:35.512664Z","shell.execute_reply.started":"2024-11-11T15:52:34.398921Z","shell.execute_reply":"2024-11-11T15:52:35.511412Z"}},"outputs":[],"execution_count":45}]}